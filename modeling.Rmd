---
title: "Modeling"
author: "Mayleen"
date: "2025-07-22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, eval = FALSE)
```
# Methods

## Outlier Detection
As part of the data preprocessing, we looked for outliers to remove from the dataset so they would not interfere with detecting the true underlying patterns in the data. We'll walk through a concrete example to explain our outlier detection process, which used Gaussian Processes (GPs). Suppose an organization has revenue data for the years 2011-2021.
1. We tune a GP to their data, namely use Nelder Mead optimization with multiple starts to find the (nu, nugget) values that maximize the likelihood of the data.
2. Using the optimal nu and nugget values, we then do a leave-one-out style process:
  * We fit a GP to all that organization's data except one year, e.g. 2012-2021, or 2011-2019 and 2021; so we fit a different GP for each year but that year is left out; note that each time we recompute sigma^2 and scale the covariance matrix accordingly
3. With each GP, we predict the "missing" year and compute the standardized residual since we have the true reported revenue for that year. If any year has a standardized residual greater than 3, we label it an outlier. You can see some of the results in gp_outlier_detection.Rmd


## Data
You can get more information about how we cleaned and processed the data from docs_cleaning.md as well as preprocessing.Rmd (which is built so you can reproduce the data we used if you go through it from start to finish).

At a high-level, one of the important pieces is that we created a "mega" dataset. Although we had data from 1989 for hundreds of thousands of organizations, not every organization existed or had data during the entire 33 year period. For our prediction method (which we'll get into more detail on later), we needed a dataset that had a record for every organization for every year over that 33 year period. We did this with some imputation. You can see more step by step details in the Creating "Full" Dataset subsection of preprocessing.Rmd. 

As an example, suppose an organization only had reported data for 2008-2016. From 1989-2007, we padded their revenue with 0's (as there's a strong chance the organization did not exist or was too small to appear in the dataset prior to 2008). From 2016-2021 we also padded their revenue with 0's, since there's a strong likelihood the organization died. It is however possible that they simply changed nonprofit category or merged with another nonprofit, so this system is not perfect. If there were any missing revenues from 2008 to 2016 or if there were outliers detected, we imputed the revenue for that year using Gaussian Processes (GPs). For example, if this organization had missing data in 2010, we fit a GP to their data in 2008, 2009, and 2011-2016 then used the GP to predict revenue in 2010.

Once every organization had a revenue for each year from 1989-2021 we moved on to prediction.

## Prediction
The gist of what our prediction model does is as follows, given 2-5 years of revenue history and the NTEE category for an organization, as well 1-3 years of a prediction period (set by the user):
Suppose the user inputs 3 years of data (`n.data = 3`) and wants to predict two years (`n.predict = 2`)
1. We first look through the full ("mega") dataset for organizations in the same NTEE category that have similar revenue history at any point in time from 1989-2021
  * We do nearest neighbors strictly on the revenue values. We look at every contiguous set of `n.data` years of revenue for other organizations in their NTEE category and do nearest neighbors with Euclidean distance. 
  * For every `n.data` year period, we select the top 7 nearest neighbors
2. We then filter out any organizations where more than 1/3 of their data is imputed in the `n.data + n.predict` years of data we would use (since when we train the GP we want to use as much real data as possible)
3. We now have a collection of about 7 organizations per window, we order by distance and select the top 5 neighbors.
4. After selecting the top 5 neighbors, we fit a GP to their data for the `n.data + n.predict` period of each neighbor. For example, one neighbor might have matched on the `n.data` year period 2010-2012, therefore we use the next `n.predict` years (2013-2014) to help us "see the future". But the exact years may be different for each neighbor.
  * we tune the GP to get the optimal nu and nugget values
5. Finally, we predict the organization's future revenue using the GP!


# Evaluation: How well does our prediction scheme work?
This part of the notebook assumes you have already created the file PREPROCESSING/processed_mega_df.rds (refer to preprocessing.Rmd section Creating "Full" Dataset)
## Load Data and Libraries
```{r, message = FALSE}
library(readr)
library(tidyverse, warn.conflicts = FALSE)
library(data.table)
library(dplyr, warn.conflicts = FALSE)
library(RANN)
library(fields)
library(ggplot2)
library(cowplot)
library(lhs) # for latin hypercube sampling

df <- readRDS("PREPROCESSING/processed_mega_df.rds")
```

## Leave one out (LOO)-style procedure
The actual procedure happens in SCRIPTS/model_LOO_eval.R, but there is one file needed in that script that we generate here. The idea behind the LOO-style procedure is we predict three years of data for each organization using their three years of data prior, but we intentionally predict on years we have data for them so we can compute errors! 
```{r}
# End goal: all.orgs.data is a subset of df with the following columns: EIN2, TAX_YEAR, TOT_REV, PREDICT
# PREDICT is boolean, TRUE if this is a year we are predicting on. Any records set to FALSE will be used as the org's history
# For each EIN2 should only contain the records we are using as history and the records we will predict
n.data = 3
n.predict = 3
# Group and get random, continous set of n.data+n.predict rows; assumes each EIN already sorted by TAX_YEAR
result <- df |> filter(IMPUTE_STATUS == "original") |>
      group_by(EIN2) |>
      group_modify(~{
            total_keep <- n.data + n.predict
            num_rows <- nrow(.x)
            
            # Randomly pick a valid starting index
            start_idx <- sample(1:(num_rows - total_keep + 1), 1)
            end_idx <- start_idx + total_keep - 1

            subset <- .x[start_idx:end_idx, ] # Get subset of size length n.data + n.predict of rows
            
            subset <- subset |> mutate(PREDICT = c(rep(FALSE, n.data), rep(TRUE, n.predict))) # Add PREDICT column
            return(subset)
      }) |>
      ungroup()

# Make sure we didn't accidentally pick a subset where each TOT_REV value is equal to 0 
# center the log revenue
result <- result |>
      group_by(EIN2) |>
      mutate(DEMEANED_REV = TOT_REV - mean(TOT_REV)) |>
      ungroup()

# For each org, get indicator of whether or not they reported same tot_rev value each year
result <- left_join(result, 
                result |> group_by(EIN2) |> summarize(all0 = all(TOT_REV == 0)), 
                by = "EIN2")

result <- result |> filter(!all0)

result <- result |> select(EIN2, TAX_YEAR, TOT_REV, NTEE, PREDICT)
saveRDS(as.data.table(result), "MODEL/nearest_neighbors/all_orgs_data.rds")
```

## Results of LOO-style procedure
```{r}
all.orgs.data <- readRDS("MODEL/nearest_neighbors/all_orgs_data.rds")
res <- readRDS("MODEL/nearest_neighbors/res_nn.rds")
res.pars <- readRDS("MODEL/nearest_neighbors/res_parameters.rds")
res.predictions <- readRDS("MODEL/nearest_neighbors/res_predictions.rds")
```

```{r}
# End result: error between TRUE and PREDICTED values (RMSE) and indicator of whether predictions fall inside confidence interval

# Add shifted YEAR variable
all.orgs.data <- all.orgs.data |> 
      filter(EIN2 %in% names(res.predictions)) |>
      group_by(EIN2) |>
      mutate(YEAR = row_number()) |>
      ungroup()
      
# Extract predictions
start.time <- Sys.time() # 37min
df.predictions <- do.call(rbind, lapply(names(res.predictions), function(id) {
data.frame(EIN2 = id,
           YEAR = res.predictions[[id]]$YEAR,
           TOT_REV.pred = res.predictions[[id]]$TOT_REV,
           SE = res.predictions[[id]]$standard_errors,
           MEAN = res.predictions[[id]]$MEAN)
}))
print(Sys.time() - start.time)
saveRDS(df.predictions, "MODEL/nearest_neighbors/predictions_df.rds")

df.predictions <- readRDS("MODEL/nearest_neighbors/predictions_df.rds") |> mutate(TOT_REV.pred = TOT_REV.pred + MEAN) |> select(-MEAN)

# Merge predictions and standard errors with true data
df.predictions <- df.predictions |> left_join(all.orgs.data |> filter(PREDICT), by = c("EIN2", "YEAR")) # get true and predicted values
df.predictions <- df.predictions |> select(-PREDICT)  |> 
      left_join(res |> filter(IMPUTE_STATUS == "original") |> 
                      group_by(ORIGINAL_ORG) |>
                      summarize(DEG.FREEDOM = n()-1) |> 
                      ungroup() |> rename(EIN2 = ORIGINAL_ORG), 
                by = "EIN2") # compute degrees of freedom (number of original records for neighbors - 1)

# Compute confidence intervals
df.predictions <- df.predictions  |> mutate(CI.LOWER = TOT_REV.pred - qt(0.95, df = DEG.FREEDOM) * SE,
                        CI.UPPER = TOT_REV.pred + qt(0.95, df = DEG.FREEDOM) * SE)

# Compute error between predicted and true values
df.predictions <- df.predictions  |> 
  mutate(REL_ERROR = abs(TOT_REV.pred - TOT_REV)/TOT_REV,
         IN_CI = (TOT_REV >= CI.LOWER & TOT_REV <= CI.UPPER))

summary.stats <- df.predictions |> group_by(EIN2) |> 
      summarize(IN_CI.prop = sum(IN_CI)/n(), 
                RMSE = sqrt(sum((TOT_REV - TOT_REV.pred)**2)/n()),
                MEAN = sum(TOT_REV)/n(),
                RMSE.norm.mm = RMSE/(max(TOT_REV)-min(TOT_REV)),
                RMSE.norm.mean = RMSE/MEAN)

summary.stats <- summary.stats |> filter(RMSE.norm.mm != Inf)

RMSE.all <- sum((df.predictions$TOT_REV - df.predictions$TOT_REV.pred)**2)/nrow(df.predictions)

var.mean <- sum((df.predictions$TOT_REV - mean(df.predictions$TOT_REV))**2)
var.pred <- sum((df.predictions$TOT_REV - df.predictions$TOT_REV.pred)**2)
r.squared <- (var.mean - var.pred)/var.mean


cat("\n",
    "RMSE: ", RMSE.all, 
    "\nRMSE/(max-min): ", RMSE.all / (max(df.predictions$TOT_REV.pred) - min(df.predictions$TOT_REV.pred)), 
    "\nRMSE/mean: ", RMSE.all/mean(df.predictions$TOT_REV.pred),
    "\nR^2:", r.squared,
    "\n")


table(summary.stats$IN_CI.prop)
```

### Plots
```{r}
# Long version for plots
df.predictions.long <- readRDS("MODEL/nearest_neighbors/predictions_df.rds") |> 
      mutate(TOT_REV.pred = TOT_REV.pred + MEAN) |> 
      select(-MEAN) |> 
      left_join(all.orgs.data |> filter(PREDICT), by = c("EIN2", "YEAR")) # get true and predicted values
df.predictions.long <- df.predictions.long |> select(-PREDICT)  |> 
      left_join(res |> filter(IMPUTE_STATUS == "original") |> 
                      group_by(ORIGINAL_ORG) |>
                      summarize(DEG.FREEDOM = n()-1) |> 
                      ungroup() |> rename(EIN2 = ORIGINAL_ORG), 
                by = "EIN2") # compute degrees of freedom (number of original records for neighbors - 1)
df.predictions.long <- df.predictions.long |>
      pivot_longer(cols = c(TOT_REV, TOT_REV.pred), names_to = "IMPUTE_STATUS", values_to = "revenue") |>
      mutate(IMPUTE_STATUS = recode(IMPUTE_STATUS,
                           "TOT_REV" = "original",
                           "TOT_REV.pred" = "predicted")) |> 
      mutate(SE = case_when(IMPUTE_STATUS == "predicted" ~ SE,
                            IMPUTE_STATUS == "original" ~ 0)) |> 
      rename(TOT_REV = revenue) # separate the true TOT_REV and predicted TOT_REV into different rows

df.predictions.long <- bind_rows(df.predictions.long,
                            all.orgs.data |> filter(!PREDICT) |> semi_join(df.predictions, by = "EIN2") |> mutate(SE = 0, IMPUTE_STATUS = "original"))

df.predictions.long <- df.predictions.long |> arrange(EIN2, YEAR) |> select(-PREDICT)

eins <- (summary.stats |> filter(IN_CI.prop == 0) |> arrange(desc(RMSE)))$EIN2
eins2  <- (summary.stats |> arrange(desc(RMSE.norm.mm)))$EIN2
eins3  <- (summary.stats |> arrange((RMSE.norm.mm)))$EIN2
```


```{r}
for (ein in eins3[1:10]){
      df.sub <- res |> filter(ORIGINAL_ORG == ein) |>
            group_by(EIN2, NEIGHBOR_ID) |> 
            mutate(YEAR = row_number()) |> # shift the years so everyone overlaps
            ungroup() |> 
            filter(IMPUTE_STATUS == "original") |> # only keep non-imputed data from nearest neighbors
            mutate(SE = 0)
      
      deg.freedom <- nrow(df.sub) - 1
      
      user.data <- df.predictions.long |> 
            filter(EIN2 == ein) |> 
            mutate(EIN2 = "Original", 
                   NEIGHBOR_ID = 0)
      
      df.sub <- bind_rows(df.sub, user.data) |> select(-NUM_ORIGINAL, -END_YEAR, -DISTANCE, -DEG.FREEDOM)
      
      # Confidence intervals
      df.sub <- df.sub |>
            mutate(CI.LOWER = case_when(
                        IMPUTE_STATUS == "original" ~ TOT_REV,
                        IMPUTE_STATUS == "predicted" ~ TOT_REV - qt(0.95, df = deg.freedom) * SE)) |>
            mutate(CI.UPPER = case_when(
                        IMPUTE_STATUS == "original" ~ TOT_REV,
                        IMPUTE_STATUS == "predicted" ~ TOT_REV + qt(0.95, df = deg.freedom) * SE)) |>
            mutate(LINETYPE = case_when(
                        EIN2 == "Original" ~ "original",
                        .default = "similar organizations"))
      
      p <- df.sub |> filter(IMPUTE_STATUS == "original") |>
            ggplot(mapping = aes(x = YEAR, y = TOT_REV, color = interaction(EIN2, NEIGHBOR_ID))) +
            geom_line(mapping = aes(linewidth = LINETYPE, alpha = LINETYPE)) + # the lines for each organization, with line width and opacity (alpha) varying by the variable LINETYPE
            geom_line(data = (df.sub |> filter(IMPUTE_STATUS == "predicted")), linetype="dashed", color="black", linewidth=1.5) + # add dashed portion of line to predictions for your org
            geom_point(mapping = aes(shape = interaction(EIN2, NEIGHBOR_ID), size = LINETYPE)) + # add in markers, where shape varies by org and marker size varies by LINETYPE
            geom_ribbon(data = (df.sub |> filter(IMPUTE_STATUS == "predicted")),
                              aes(ymin = CI.LOWER, ymax = CI.UPPER,fill = IMPUTE_STATUS),
                              alpha = 0.25, color = "darkgrey") + # confidence interval
            scale_color_manual(values = c( "#000000", "#009E73",  "#E8DA1D", "#0072B2", "#D55E00", "#CC79A7"), name = "Organization ID") +
            scale_shape_manual(values = c(15, 17, 18, 7, 10, 19), name = "Organization ID") +
            scale_size_manual(values = c(2.5,3.5), guide="none") +
            scale_linewidth_manual(values = c(0.75, 1), guide="none") +
            scale_alpha_manual(values = c(0.75, 1), guide="none") +
            scale_fill_manual(values = "grey", labels="95% Confidence Interval", name="") +
            scale_y_continuous(labels = scales::comma) +
            labs(x = "Year", y = "Total Revenue (USD)", title = paste("Comparing", ein, "to Similar Organizations")) + 
            theme(axis.text.x = element_text(angle = 45, vjust = 0.75, hjust=1)) + 
            theme_bw()
      print(p)
}
```

```{r}
df <- readRDS("PREPROCESSING/processed_mega_df.rds")
df.outliers <- readRDS("PREPROCESSING/candidate_outliers_df.rds")
df.original <- readRDS("PREPROCESSING/df_orginal_processed.rds")


test_eins <- eins[1:10]
ein <- test_eins[3] #"EIN-46-3265423"

df.original |> filter(EIN2 == ein) |>
            ggplot(aes(x = TAX_YEAR, y = TOT_REV)) +
            geom_line() + geom_point(aes(shape = outlier, color = outlier))

df |> filter(EIN2 == ein) |>
            ggplot(aes(x = TAX_YEAR, y = TOT_REV)) +
            geom_line() +
            geom_point(aes(shape = IMPUTE_STATUS, color = IMPUTE_STATUS))

df.outliers |> filter(EIN2 == test_eins[4])


df |> filter(EIN2 == "EIN-46-3265423") |> filter(IMPUTE_STATUS == "original")

df.predictions |> filter(EIN2 == "EIN-46-3265423")

res |> filter(ORIGINAL_ORG == "EIN-46-3265423") |> filter(IMPUTE_STATUS == "original")
```

### Confidence Intervals corrected for correlation
```{r}
res.predictions <- readRDS("MODEL/nearest_neighbors/res_predictions.rds")
df.predictions <- readRDS("MODEL/nearest_neighbors/predictions_df.rds") |> mutate(TOT_REV.pred = TOT_REV.pred + MEAN) |> select(-MEAN)

SIGMA <- lapply(res.predictions, function(x) x[["SIGMA"]])

inv.t.chol <- function(x){
      tryCatch({chol2inv(t(chol(x)))}, error = function(err) {"error!!!"})
}

# Add the true total revenue to the predictions data frame
all.orgs.data <- all.orgs.data |> group_by(EIN2) |> mutate(YEAR = row_number()) |> ungroup()
df.predictions <- df.predictions |> left_join(all.orgs.data |> select(EIN2, YEAR, TOT_REV), by = c("EIN2", "YEAR"))

# Standardize the data
df.predictions <- df.predictions |> group_by(EIN2) |>
      mutate(resid = TOT_REV - TOT_REV.pred,
             STANDARDIZED = as.numeric(SIGMA[[unique(EIN2)]] %*% resid))

# Does the standardized data fall into the interval [-1.96,1.96] (95% confidence interval)?
df.predictions <- df.predictions |> mutate(IN_95_CI = (STANDARDIZED >= -1.96 & STANDARDIZED <= 1.96))

sum(df.predictions$IN_95_CI) / nrow(df.predictions)

saveRDS(df.predictions |> select(-IN_95_CI), "MODEL/nearest_neighbors/predictions_df_standardized.rds")
```



```{r}
res <- readRDS("MODEL/nearest_neighbors/res_nn.rds")
# Add in degrees of freedom for computing confidence intervals
df.predictions <- df.predictions |> select(-PREDICT)  |> 
      left_join(res |> filter(IMPUTE_STATUS == "original") |> 
                      group_by(ORIGINAL_ORG) |>
                      summarize(DEG.FREEDOM = n()-1) |> 
                      ungroup() |> rename(EIN2 = ORIGINAL_ORG), 
                by = "EIN2") # compute degrees of freedom (number of original records for neighbors - 1)

# Compute confidence intervals
df.predictions <- df.predictions  |> mutate(CI.LOWER = TOT_REV.pred - qt(0.95, df = DEG.FREEDOM) * SE,
                        CI.UPPER = TOT_REV.pred + qt(0.95, df = DEG.FREEDOM) * SE)
```


