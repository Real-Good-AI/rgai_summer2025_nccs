---
title: "Outlier Detection with GPs"
author: "Mayleen"
date: "2025-06-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, eval = FALSE)
```

# Outlier Analysis - Full
NOTE: To run this, you would need to have run SCRIPTS/outlier_detection.R as well as the preprocessing.Rmd notebook section "Outlier Flagging and Removal"
```{r}
df <- readRDS("PREPROCESSING/df_orginal_processed.rds")
df.candidates <- readRDS("PREPROCESSING/candidate_outliers_df.rds")

res.parameters <- readRDS("PREPROCESSING/best_parameters.rds")

all.orgs.gp <-res.parameters$EIN

res.out.1 <- readRDS("PREPROCESSING/gp_res_1.rds")
res.out.2 <- readRDS("PREPROCESSING/gp_res_2.rds")
res.out.3 <- readRDS("PREPROCESSING/gp_res_3.rds")
res.out.4 <- readRDS("PREPROCESSING/gp_res_4.rds")
res.out.5 <- readRDS("PREPROCESSING/gp_res_5.rds")

# Rename
names(res.out.1) <- all.orgs.gp[1:100000]
names(res.out.2) <- all.orgs.gp[100001:200000]
names(res.out.3) <- all.orgs.gp[200001:300000]
names(res.out.4) <- all.orgs.gp[300001:399999]
names(res.out.5) <- all.orgs.gp[400000:length(all.orgs.gp)]

# Get all candidates, first I have to extract the candidates sublist from each res.out object
candidates <- c(lapply(res.out.1, function(x){x[["candidates"]]}),
                lapply(res.out.2, function(x){x[["candidates"]]}),
                lapply(res.out.3, function(x){x[["candidates"]]}),
                lapply(res.out.4, function(x){x[["candidates"]]}),
                lapply(res.out.5, function(x){x[["candidates"]]})
                )

# Filter out any orgs with no detected outliers
candidates <- Filter(function(x) length(x) > 0, candidates)

standard_errors <- c(lapply(res.out.1, function(x){x[["standard_errors"]]}),
                lapply(res.out.2, function(x){x[["standard_errors"]]}),
                lapply(res.out.3, function(x){x[["standard_errors"]]}),
                lapply(res.out.4, function(x){x[["standard_errors"]]}),
                lapply(res.out.5, function(x){x[["standard_errors"]]})
                )

predictions <- readRDS("PREPROCESSING/all_predictions.rds")
rm(res.out.1, res.out.2, res.out.3, res.out.4, res.out.5)

all.years <- c(unlist(candidates))
```

```{r}
residuals <- c(lapply(res.out.1, function(x){x[["residuals"]]}),
                lapply(res.out.2, function(x){x[["residuals"]]}),
                lapply(res.out.3, function(x){x[["residuals"]]}),
                lapply(res.out.4, function(x){x[["residuals"]]}),
                lapply(res.out.5, function(x){x[["residuals"]]})
                )
df.stres <- do.call(rbind, lapply(names(candidates), function(id) {data.frame(EIN = id, Value = candidates[[id]], STDRES = residuals[[id]])}
                                  ))
df.stres <- df.stres |> rename(EIN2 = EIN, TAX_YEAR = Value)
df.candidates <- left_join(df.candidates, df.stres)

# saveRDS(df.candidates, "PREPROCESSING/candidate_outliers_df.rds")

df.candidates <- df.candidates |> mutate(SIGN = sign(STDRES), DIFF.abs = abs(STDRES - 3), DIFF.rel = (STDRES-3)/3)
table(df.candidates$SIGN)

df.candidates |> mutate(SIGN = factor(SIGN, levels = c(1, -1))) |>
      ggplot() +
      geom_histogram(mapping = aes(x = TAX_YEAR, group = factor(SIGN), fill = factor(SIGN)), color = "black", bins = length(unique(all.years))) +
      scale_fill_manual(values = c("#1796D2", "#FDC010"), labels = c("Positive", "Negative")) +
      labs(x = "Year", title = "Outliers per Year", fill = "Outlier Type")
```


```{r}
num.per.year <- table(all.years)
total.per.year <- table(df$TAX_YEAR)

num.per.year <- as.data.frame(num.per.year) |> rename(YEAR = all.years) 
total.per.year <- as.data.frame(total.per.year) |> rename(YEAR = Var1)

per.year.df <- full_join(num.per.year, total.per.year, by = "YEAR", suffix = c(".out", ".total")) |>
      mutate(Percent = Freq.out/Freq.total)

tst <- df.candidates |> group_by(TAX_YEAR, SIGN) |> summarize(count = n())

per.year.df[,"positive"] <- tst |> ungroup() |> filter(SIGN == 1) |> select(count)
per.year.df[,"negative"] <- tst |> ungroup() |> filter(SIGN == -1) |> select(count)

per.year.df <- per.year.df |> rename(year = YEAR, total.outliers = Freq.out, total.data = Freq.total, prop.outliers = Percent, total.pos = positive, total.neg = negative) |> mutate(prop.pos = total.pos/total.data, prop.neg = total.neg/total.data)
```

```{r}
# Reshape data to long format
df.long <- per.year.df |> 
  select(year, prop.pos, prop.neg) |> 
  pivot_longer(cols = c(prop.pos, prop.neg), 
               names_to = "outlier_type", 
               values_to = "proportion") |> 
  mutate(outlier_type = recode(outlier_type, 
                               prop.pos = "Positive", 
                               prop.neg = "Negative"))
df.long <- df.long |> mutate(outlier_type = factor(outlier_type, levels = c("Positive", "Negative")))

ggplot(df.long, aes(x = factor(year), y = proportion*100, fill = outlier_type)) +
      geom_bar(stat = "identity", color = "black") +
      labs(x = "Year", y = "Percent", fill = "Outlier Type", title = "Percent of Outliers per Year") +
      theme(axis.text.x = element_text(angle = 45, vjust = 0.75, hjust=1)) +
      scale_fill_manual(values = c("#1796D2",  "#FDC010"))
```




# Outlier Analysis - training set

```{r, eval = TRUE, message = FALSE}
library(fields)
library(readr)
library(tidyverse, warn.conflicts = FALSE)
library(data.table)
library(dplyr, warn.conflicts = FALSE)
library(ggplot2)
library(tidyr)
library(mvtnorm)
library(pracma)
library(doParallel)
library(lhs)
source("SCRIPTS/outlier_detection_helper.R")
```


```{r, eval = TRUE, message = FALSE}
df <- as.data.table(read_csv("MODEL/training.csv", show_col_types = FALSE)) |>
      group_by(EIN2) |>
      filter(!is.na(LOG_REV)) |>
      mutate(LOG_REV = LOG_REV - mean(LOG_REV), DATA_COUNT = n()) |>
      ungroup()

df <- df |> filter(DATA_COUNT >= 5)
```


```{r, eval = TRUE, message = FALSE, results='hide'}
orgs.no.change <- readRDS("MODEL/outlier_detection/full/orgs_reported_same.rds")
all.orgs <- unique(df$EIN2) 
all.orgs <- setdiff(all.orgs, orgs.no.change)

candidates.1 <- readRDS("MODEL/outlier_detection/full/full_candidates_1.rds")
tst <- readRDS("MODEL/outlier_detection/full/full_sigmas_1.rds")
res.out2 <- readRDS("MODEL/outlier_detection/full/outlier_res_2.rds")
res.out3 <- readRDS("MODEL/outlier_detection/full/outlier_res_3.rds")

# get vector of all years
sapply(res.out2, function(x){x[["candidates"]]})
all.years <- c(unlist(candidates.1), unlist(sapply(res.out2, function(x){unlist(x[["candidates"]])})), unlist(sapply(res.out3, function(x){unlist(x[["candidates"]])})))

# get number of years identified per org
num.per.org <- c(sapply(candidates.1, function(x){length(x)}), sapply(res.out2, function(x){length(x[["candidates"]])}), sapply(res.out3, function(x){length(x[["candidates"]])}))

# get number of years total per org (i.e. size of time series)
len.per.org <- c(sapply(tst, function(x){length(x)}), sapply(res.out2, function(x){length(x[["sigs"]])}), sapply(res.out3, function(x){length(x[["sigs"]])}))

# rename 
# names(res.out2) <- all.orgs[100001:200000]
# names(res.out3) <- all.orgs[200001:length(all.orgs)]

# list of candidates?
# candidates.2 <- lapply(res.out2, function(x){x[["candidates"]]})
# candidates.3 <- lapply(res.out3, function(x){x[["candidates"]]})

# saveRDS(candidates.2, "MODEL/outlier_detection/full_candidates_2.rds")
# saveRDS(candidates.3, "MODEL/outlier_detection/full_candidates_3.rds")
# saveRDS(res.out2, "MODEL/outlier_detection/outlier_res_2.rds")
# saveRDS(res.out3, "MODEL/outlier_detection/outlier_res_3.rds")

candidates <- c(candidates.1, readRDS("MODEL/outlier_detection/full/full_candidates_2.rds"), readRDS("MODEL/outlier_detection/full/full_candidates_3.rds"))

rm(candidates.1, tst, res.out2, res.out3)
```


How many outliers do we identify per org? If we removed all candidate outliers, how much data would we lose?
```{r, echo=FALSE, eval=TRUE}
table(num.per.org)
barplot(table(num.per.org), main = "Number of Outliers Detected per Org", xlab = "Number of Outliers", ylab = "Number of Orgs")
print(paste("Total # of records:", nrow(df), ", Outliers identified:", length(all.years), ", # of records left:", nrow(df) - length(all.years), "Data loss:", length(all.years)/nrow(df)))
```

How many outliers do we identify per year? How many are positive versus negative?
```{r, echo=FALSE, eval=TRUE}
df.stres <- readRDS("MODEL/outlier_detection/full/outlier_resids_DF.rds")
table(df.stres$SIGN)
df.stres |> mutate(SIGN = factor(SIGN, levels = c(1, -1))) |>
      ggplot() +
      geom_histogram(mapping = aes(x = Value, group = factor(SIGN), fill = factor(SIGN)), color = "black", bins = length(unique(all.years))) +
      scale_fill_manual(values = c("#1796D2", "#FDC010"), labels = c("Positive", "Negative")) +
      labs(x = "Year", title = "Outliers per Year", fill = "Outlier Type")
```

```{r}
df.stres |> 
      filter(SIGN == -1) |> 
      ggplot() +
      geom_histogram(mapping = aes(x = Value), fill = "#1796D2", color = "black", bins = length(unique(all.years))) +
      labs(x = "Year", title = "Negative Outliers per Year")

df.stres |> 
      filter(SIGN == 1) |> 
      ggplot() +
      geom_histogram(mapping = aes(x = Value), fill = "#FDC010", color = "black", bins = length(unique(all.years))) +
      labs(x = "Year", title = "Positive Outliers per Year")
```


What proportion of the records each year are identified as outliers, positive versus negative?
```{r, eval = TRUE}
per.year.df <- readRDS("MODEL/outlier_detection/full_training/per_year_DF.rds")

# Reshape data to long format
df.long <- per.year.df |> 
  select(year, prop.pos, prop.neg) |> 
  pivot_longer(cols = c(prop.pos, prop.neg), 
               names_to = "outlier_type", 
               values_to = "proportion") |> 
  mutate(outlier_type = recode(outlier_type, 
                               prop.pos = "Positive", 
                               prop.neg = "Negative"))
df.long <- df.long |> mutate(outlier_type = factor(outlier_type, levels = c("Positive", "Negative")))

ggplot(df.long, aes(x = factor(year), y = proportion, fill = outlier_type)) +
      geom_bar(stat = "identity", color = "black") +
      labs(x = "Year", y = "Proportion", fill = "Outlier Type", title = "Proportion of Outliers per Year") +
      theme(axis.text.x = element_text(angle = 45, vjust = 0.75, hjust=1)) +
      scale_fill_manual(values = c("#1796D2",  "#FDC010"))

ggplot(df.long |> filter(outlier_type == "Negative"), aes(x = factor(year), y = proportion)) +
      geom_bar(stat = "identity", color = "black", fill = "#FDC010") +
      labs(x = "Year", y = "Proportion", title = "Proportion of Negative Outliers per Year") +
      theme(axis.text.x = element_text(angle = 45, vjust = 0.75, hjust=1))
```

What is the distribution of the standardized residuals of outliers per year?
```{r, eval = TRUE}
quantile(df.stres$STDRES, probs = seq(0,1,0.01))[c(1,2,3,51,76,99,100,101)]

# Create alternating color labels
df.stres <- df.stres %>%
  mutate(Year = factor(Value),
         ColorGroup = ifelse(as.numeric(Year) %% 2 == 0, "Even", "Odd"))

# Plot with alternating fill
ggplot(df.stres, aes(x = Year, y = STDRES, fill = ColorGroup)) +
  geom_boxplot(outlier.shape = NA) +  # remove outlier dots if too cluttered
  theme_minimal() +
  scale_fill_manual(values = c("Even" = "white", "Odd" =  "grey")) +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.75, hjust=1),
        legend.position = "none") +  # remove legend if color is just for readability
  labs(x = "Year", title = "Standardized Residuals of Outliers per Year") +
  ylim(-15, 8)
```
```{r}
ggplot(df.stres, mapping = aes(x = factor(Value), y = STDRES, group = factor(Value))) +
      geom_boxplot() +
      theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
      labs(x = "Year", title = "Standardized Residuals of Outliers per Year") +
      ylim(-15, 8)
```


```{r, eval=TRUE}
candidates <- Filter(function(x) length(x) > 0, candidates)
df.sub <- df |> filter(EIN2 %in% names(candidates)) |> rename(EIN = EIN2)
df.sub <- left_join(df.sub, as.data.table(num.per.org, keep.rownames=TRUE) |> rename(EIN = rn), by = "EIN")

# pivot from long to a wider format so that each record corresponds to a single EIN
df.stres.wide <- df.stres |> 
      group_by(EIN, SIGN) |> 
      summarize(count = n()) |>
      mutate(SIGN = ifelse(SIGN == 1, "count.positive", "count.negative")) |>
      pivot_wider(names_from = SIGN, values_from = count, values_fill = 0) |>
      ungroup()

df.sub <- left_join(df.sub, df.stres.wide, by = "EIN")

# Every record for a particular EIN will have the same values for num.per.org, count.positive, and count.negative, so I just need to grab one record from each EIN
tst <- df.sub |> 
      group_by(EIN) |>
      slice(1) |>
      ungroup()

n.outliers <- sum(tst$num.per.org)

# Compute proportion of outliers per NTEE category
tst <- tst |>
      group_by(NTEE) |>
      summarize(prop = sum(num.per.org)/n.outliers, 
                prop.neg = sum(count.negative)/n.outliers, 
                prop.pos = sum(count.positive)/n.outliers,
                tot.outliers = sum(num.per.org),
                tot.neg = sum(count.negative),
                tot.pos = sum(count.positive)) 

# Reshape data to long format
tst <- tst |>
      select(NTEE, prop.pos, prop.neg, tot.pos, tot.neg) |>
      pivot_longer(cols = c(prop.pos, prop.neg, tot.pos, tot.neg), 
                   names_to = c(".value", "outlier_type"), 
                   names_pattern = "(prop|tot)\\.(pos|neg)") |>
      mutate(outlier_type = recode(outlier_type,
                                   pos = "Positive",
                                   neg = "Negative"))

tst <- tst |> mutate(outlier_type = factor(outlier_type, levels = c("Positive", "Negative")))
ntee_labs <- c("Arts, Culture, & Humanities", "Education (minus Universities)", "Environment & Animals", "Health (minus Hospitals)", "Human Services", "Hospitals", "International, Foreign Affairs", "Mutual/Membership Benefit", "Public, Societal Benefit", "Religion Related", "Universities", "Other")
```

What proportion of the overall data do each of the subsectors share? What proportion of outliers do each of the subsectors share?
```{r, eval = TRUE}
df |> group_by(NTEE) |> 
      summarize(data.count = n(), data.prop = n()/nrow(df)) |>
      ggplot(aes(x = NTEE, y = data.prop)) +
      geom_bar(stat = "identity", color = "black") + 
      labs(x = "NTEE", y = "Proportion", title = "Proportion of total data by subsector") +
      scale_x_discrete(labels = ntee_labs) +
      theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=0.9))

tst |>
      ggplot(aes(x = factor(NTEE), y = prop, fill = outlier_type)) +
      geom_bar(stat = "identity", color = "black") + 
      labs(x = "NTEE", y = "Proportion", title = "Proportion of TOTAL outliers by subsector and type", fill = "Outlier Type") +
      scale_x_discrete(labels = ntee_labs) +
      theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=0.9)) +
      scale_fill_manual(values = c("#1796D2",  "#FDC010"))
```

What about the spread of outliers within each group? 
```{r, eval = TRUE}
left_join(tst, df |> group_by(NTEE) |> summarize(data.count = n()), by = "NTEE") |>
      ggplot(aes(x = factor(NTEE), y = tot/data.count, fill = outlier_type)) +
      geom_bar(stat = "identity", color = "black") + 
      labs(x = "NTEE", y = "Proportion", 
           title = "Proportion of outlier in each subsector & type (from total data in that group)",
           fill = "Outlier Type") +
      scale_x_discrete(labels = ntee_labs) +
      theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=0.9)) +
      scale_fill_manual(values = c("#1796D2",  "#FDC010"))
```

```{r, eval=TRUE}
# Per year, per category, I want the proportion of positive and negative outliers

# First, I need to get df.sub where instead of num.per.org, count.positive, and count.negative, for that record I have to have a count of the number of positive and negative outliers
df.stres <- df.stres |> rename(TAX_YEAR = Value)
df.sub <- df.sub |> left_join(df.stres |> select(EIN, TAX_YEAR, SIGN), by = c("EIN", "TAX_YEAR")) |>
      mutate(positive = ifelse(SIGN == 1, 1, 0),
             negative = ifelse(SIGN == -1, 1, 0)) |>
      mutate(positive = replace_na(positive, 0),
             negative = replace_na(negative, 0)) |>
      select(-SIGN) 


tst <- df.sub |> 
      group_by(NTEE, TAX_YEAR) |>
      summarize(tot.neg = sum(negative),
                tot.pos = sum(positive),
                total = n())

# Reshape data to long format
tst <- tst |>
      pivot_longer(cols = c(tot.pos, tot.neg), 
                   names_to = "outlier_type", 
                   values_to = "outlier") |>
      mutate(outlier_type = recode(outlier_type,
                                   tot.pos = "Positive",
                                   tot.neg = "Negative"))

tst <- left_join(x = tst, 
          y = per.year.df |> mutate(TAX_YEAR = as.numeric(as.character(year))) |> select(TAX_YEAR, total.outliers), 
          by = "TAX_YEAR")

tst <- tst |> mutate(outlier_type = factor(outlier_type, levels = c("Positive", "Negative")))
```

What proportion of outliers does each subsector take up per year out of the total number of outliers in that year?
```{r, eval = TRUE}
ntee_labs <- c("Arts, Culture, & Humanities", "Education (minus Universities)", "Environment & Animals", "Health (minus Hospitals)", "Human Services", "Hospitals", "International, Foreign Affairs", "Mutual/Membership Benefit", "Public, Societal Benefit", "Religion Related", "Universities", "Other")

ggplot(tst |> filter(NTEE != "NA"), aes(x = TAX_YEAR, y = outlier/total.outliers, fill = outlier_type)) +
      geom_bar(stat = "identity") +
      facet_wrap(~NTEE, nrow = 4) +
      labs(x = "Year", y = "Proportion", fill = "Outlier Type", title = "Proportion of Outliers per Year, by subsector (out of total # of outliers that year)") +
      theme(axis.text.x = element_text(angle = 45, vjust = 0.75, hjust=1)) +
      scale_fill_manual(values = c("#1796D2",  "#FDC010")) +
      scale_x_continuous(breaks=seq(1989,2021,5))
```
What about the proportion of outliers per year per subsector, but out of the total number of outliers in that year-subsector pair?
```{r, eval=TRUE}
ggplot(tst |> filter(NTEE != "NA"), aes(x = TAX_YEAR, y = outlier/total, fill = outlier_type)) +
      geom_bar(stat = "identity") +
      facet_wrap(~NTEE, nrow = 4) +
      labs(x = "Year", y = "Proportion", fill = "Outlier Type", title = "Proportion of Outliers per Year, NTEE (from total # of outliers in ntee-year pair)") +
      theme(axis.text.x = element_text(angle = 45, vjust = 0.75, hjust=1)) +
      scale_fill_manual(values = c("#1796D2",  "#FDC010")) +
      scale_x_continuous(breaks=seq(1989,2021,5))
```


```{r,eval=TRUE}
# Every record for a particular EIN will have the same values for num.per.org, count.positive, and count.negative, so I just need to grab one record from each EIN
tst <- df.sub |> 
      group_by(EIN) |>
      slice(1) |>
      ungroup()

n.outliers <- sum(tst$num.per.org)

# Compute proportion of outliers per DIVISION category
tst <- tst |>
      group_by(DIVISION) |>
      summarize(prop = sum(num.per.org)/n.outliers, 
                prop.neg = sum(count.negative)/n.outliers, 
                prop.pos = sum(count.positive)/n.outliers,
                tot.outliers = sum(num.per.org),
                tot.neg = sum(count.negative),
                tot.pos = sum(count.positive)) 

# Reshape data to long format
tst <- tst |>
      select(DIVISION, prop.pos, prop.neg, tot.pos, tot.neg) |>
      pivot_longer(cols = c(prop.pos, prop.neg, tot.pos, tot.neg), 
                   names_to = c(".value", "outlier_type"), 
                   names_pattern = "(prop|tot)\\.(pos|neg)") |>
      mutate(outlier_type = recode(outlier_type,
                                   pos = "Positive",
                                   neg = "Negative"))

tst <- tst |> mutate(outlier_type = factor(outlier_type, levels = c("Positive", "Negative")))
```



What proportion of the overall data do each of the divisions share? What proportion of outliers do each of the divisions share?
```{r, eval = TRUE}
df |> group_by(DIVISION) |> 
      summarize(data.count = n(), data.prop = n()/nrow(df)) |>
      ggplot(aes(x = DIVISION, y = data.prop)) +
      geom_bar(stat = "identity", color = "black") + 
      labs(x = "Division", y = "Proportion", title = "Proportion of total data by division") +
      theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=0.9))

tst |> ggplot(aes(x = DIVISION, y = prop, fill = outlier_type)) +
      geom_bar(stat = "identity", color = "black") + 
      labs(x = "Division", y = "Proportion", title = "Proportion of TOTAL outliers by division and type", fill = "Outlier Type") +
      theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=0.9)) +
      scale_fill_manual(values = c("#1796D2",  "#FDC010"))
```
What about the spread of outliers within each group? 
```{r, eval = TRUE}
left_join(tst, df |> group_by(DIVISION) |> summarize(data.count = n()), by = "DIVISION") |>
      ggplot(aes(x = DIVISION, y = tot/data.count, fill = outlier_type)) +
      geom_bar(stat = "identity", color = "black") + 
      labs(x = "Division", y = "Proportion", 
           title = "Proportion of outlier in each division & type (from total data in that group)",
           fill = "Outlier Type") +
      theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=0.9)) +
      scale_fill_manual(values = c("#1796D2",  "#FDC010"))
```


```{r, eval = TRUE}
tst <- df.sub |> 
      group_by(DIVISION, TAX_YEAR) |>
      summarize(tot.neg = sum(negative),
                tot.pos = sum(positive),
                total = n())

# Reshape data to long format
tst <- tst |>
      pivot_longer(cols = c(tot.pos, tot.neg), 
                   names_to = "outlier_type", 
                   values_to = "outlier") |>
      mutate(outlier_type = recode(outlier_type,
                                   tot.pos = "Positive",
                                   tot.neg = "Negative"))

tst <- left_join(x = tst, 
          y = per.year.df |> mutate(TAX_YEAR = as.numeric(as.character(year))) |> select(TAX_YEAR, total.outliers), 
          by = "TAX_YEAR")

tst <- tst |> mutate(outlier_type = factor(outlier_type, levels = c("Positive", "Negative")))

ggplot(tst |> filter(DIVISION != "NA"), aes(x = TAX_YEAR, y = outlier/total.outliers, fill = outlier_type)) +
      geom_bar(stat = "identity") +
      facet_wrap(~DIVISION, nrow = 4) +
      labs(x = "Year", y = "Proportion", fill = "Outlier Type", title = "Proportion of Outliers per Year, Division (out of total # of outliers that year)") +
      theme(axis.text.x = element_text(angle = 45, vjust = 0.75, hjust=1)) +
      scale_fill_manual(values = c("#1796D2",  "#FDC010")) +
      scale_x_continuous(breaks=seq(1989,2021,5))

ggplot(tst |> filter(DIVISION != "NA"), aes(x = TAX_YEAR, y = outlier/total, fill = outlier_type)) +
      geom_bar(stat = "identity") +
      facet_wrap(~DIVISION, nrow = 4) +
      labs(x = "Year", y = "Proportion", fill = "Outlier Type", title = "Proportion of Outliers per Year, Division (from total # of outliers in ntee-year pair)") +
      theme(axis.text.x = element_text(angle = 45, vjust = 0.75, hjust=1)) +
      scale_fill_manual(values = c("#1796D2",  "#FDC010")) +
      scale_x_continuous(breaks=seq(1989,2021,5))
```


```{r,eval=TRUE}
# Every record for a particular EIN will have the same values for num.per.org, count.positive, and count.negative, so I just need to grab one record from each EIN
tst <- df.sub |> 
      group_by(EIN) |>
      slice(1) |>
      ungroup()

# Compute proportion of outliers per DIVISION category
tst <- tst |>
      group_by(SIZE.CAT) |>
      summarize(prop = sum(num.per.org)/n.outliers, 
                prop.neg = sum(count.negative)/n.outliers, 
                prop.pos = sum(count.positive)/n.outliers,
                tot.outliers = sum(num.per.org),
                tot.neg = sum(count.negative),
                tot.pos = sum(count.positive)) 

# Reshape data to long format
tst <- tst |>
      select(SIZE.CAT, prop.pos, prop.neg, tot.pos, tot.neg) |>
      pivot_longer(cols = c(prop.pos, prop.neg, tot.pos, tot.neg), 
                   names_to = c(".value", "outlier_type"), 
                   names_pattern = "(prop|tot)\\.(pos|neg)") |>
      mutate(outlier_type = recode(outlier_type,
                                   pos = "Positive",
                                   neg = "Negative"))

tst <- tst |> mutate(outlier_type = factor(outlier_type, levels = c("Positive", "Negative")))

size_labs <- c("Under $100,000", "$100,000 - $499,999", "$500,000 - $999,999", "$1 Million - $4.99 Million", "$5 Million - $9.99 Million", "Above $10 Million")

df |> group_by(SIZE.CAT) |> 
      summarize(data.count = n(), data.prop = n()/nrow(df)) |>
      ggplot(aes(x = factor(SIZE.CAT), y = data.prop)) +
      geom_bar(stat = "identity", color = "black") + 
      labs(x = "Size", y = "Proportion", title = "Proportion of total data by size") +
      theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=0.9)) +
      scale_x_discrete(labels = size_labs)

tst |> ggplot(aes(x = factor(SIZE.CAT), y = prop, fill = outlier_type)) +
      geom_bar(stat = "identity", color = "black") + 
      labs(x = "Size", y = "Proportion", title = "Proportion of TOTAL outliers by size and type", fill = "Outlier Type") +
      theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=0.9)) +
      scale_fill_manual(values = c("#1796D2",  "#FDC010")) +
      scale_x_discrete(labels = size_labs)

left_join(tst, df |> group_by(SIZE.CAT) |> summarize(data.count = n()), by = "SIZE.CAT") |>
      ggplot(aes(x = factor(SIZE.CAT), y = tot/data.count, fill = outlier_type)) +
      geom_bar(stat = "identity", color = "black") + 
      labs(x = "Size", y = "Proportion", 
           title = "Proportion of outlier in each size & type (from total data in that group)",
           fill = "Outlier Type") +
      theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=0.9)) +
      scale_fill_manual(values = c("#1796D2",  "#FDC010")) +
      scale_x_discrete(labels = size_labs)
```

```{r, eval = TRUE}
tst <- df.sub |> 
      group_by(SIZE.CAT, TAX_YEAR) |>
      summarize(tot.neg = sum(negative),
                tot.pos = sum(positive),
                total = n())

# Reshape data to long format
tst <- tst |>
      pivot_longer(cols = c(tot.pos, tot.neg), 
                   names_to = "outlier_type", 
                   values_to = "outlier") |>
      mutate(outlier_type = recode(outlier_type,
                                   tot.pos = "Positive",
                                   tot.neg = "Negative"))

tst <- left_join(x = tst, 
          y = per.year.df |> mutate(TAX_YEAR = as.numeric(as.character(year))) |> select(TAX_YEAR, total.outliers), 
          by = "TAX_YEAR")

tst <- tst |> mutate(outlier_type = factor(outlier_type, levels = c("Positive", "Negative")))

size_labs <- c("1"="Under $100,000", "2"="$100,000 - $499,999", "3"="$500,000 - $999,999", "4"="$1 Million - $4.99 Million", "5"="$5 Million - $9.99 Million", "6"="Above $10 Million")

ggplot(tst |> filter(SIZE.CAT != "NA"), aes(x = TAX_YEAR, y = outlier/total.outliers, fill = outlier_type)) +
      geom_bar(stat = "identity") +
      facet_wrap(~SIZE.CAT, nrow = 4, labeller = as_labeller(size_labs)) +
      labs(x = "Year", y = "Proportion", fill = "Outlier Type", title = "Proportion of Outliers per Year, Size (out of total # of outliers that year)") +
      theme(axis.text.x = element_text(angle = 45, vjust = 0.75, hjust=1)) +
      scale_fill_manual(values = c("#1796D2",  "#FDC010")) +
      scale_x_continuous(breaks=seq(1989,2021,5))

ggplot(tst |> filter(SIZE.CAT != "NA"), aes(x = TAX_YEAR, y = outlier/total, fill = outlier_type)) +
      geom_bar(stat = "identity") +
      facet_wrap(~SIZE.CAT, nrow = 4, labeller = as_labeller(size_labs)) +
      labs(x = "Year", y = "Proportion", fill = "Outlier Type", title = "Proportion of Outliers per Year, Size (from total # of outliers in ntee-year pair)") +
      theme(axis.text.x = element_text(angle = 45, vjust = 0.75, hjust=1)) +
      scale_fill_manual(values = c("#1796D2",  "#FDC010")) +
      scale_x_continuous(breaks=seq(1989,2021,5))
```



```{r}
hist(all.years, breaks = length(unique(all.years)))
num.per.year <- table(all.years)
total.per.year <- table(df$TAX_YEAR)

num.per.year <- as.data.frame(num.per.year) |> rename(YEAR = all.years) 
total.per.year <- as.data.frame(total.per.year) |> rename(YEAR = Var1)

per.year.df <- full_join(num.per.year, total.per.year, by = "YEAR", suffix = c(".out", ".total")) |>
      mutate(Percent = Freq.out/Freq.total)

ggplot(per.year.df, aes(x = YEAR, y = Percent)) +
      geom_point(size = 3) +
      labs(y = "Proportion", title = "Number of outlier years / Total records per year") +
      theme(axis.text.x = element_text(angle = 45, vjust = 0.75, hjust=1))
```

```{r}
tst <- df.stres |> group_by(Value, SIGN) |> summarize(count = n())

per.year.df[,"positive"] <- tst |> ungroup() |> filter(SIGN == 1) |> select(count)
per.year.df[,"negative"] <- tst |> ungroup() |> filter(SIGN == -1) |> select(count)

per.year.df <- per.year.df |> rename(year = YEAR, total.outliers = Freq.out, total.data = Freq.total, prop.outliers = Percent, total.pos = positive, total.neg = negative) |> mutate(prop.pos = total.pos/total.data, prop.neg = total.neg/total.data)

#saveRDS(per.year.df, "MODEL/outlier_detection/full/per_year_DF.rds")

# Reshape data to long format
df.long <- per.year.df |> 
  select(year, prop.pos, prop.neg) |> 
  pivot_longer(cols = c(prop.pos, prop.neg), 
               names_to = "outlier_type", 
               values_to = "proportion") |> 
  mutate(outlier_type = recode(outlier_type, 
                               prop.pos = "Positive", 
                               prop.neg = "Negative"))

ggplot(df.long, aes(x = factor(year), y = proportion, fill = outlier_type)) +
      geom_bar(stat = "identity") +
      labs(x = "Year", y = "Proportion of Outliers", fill = "Outlier Type") +
      theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
      scale_fill_manual(values = c("#1796D2",  "#FDC010"))
```



```{r}
pred.1 <- readRDS("MODEL/outlier_detection/full/full_predictions_1.rds")
se.1 <- readRDS("MODEL/outlier_detection/full/full_se_1.rds")
res.out2 <- readRDS("MODEL/outlier_detection/full/outlier_res_2.rds")
res.out3 <- readRDS("MODEL/outlier_detection/full/outlier_res_3.rds")

# list of standard errors and predictions
pred.2 <- lapply(res.out2, function(x){x[["predictions"]]})
se.2 <- lapply(res.out2, function(x){x[["standard_errors"]]})

pred.3 <- lapply(res.out3, function(x){x[["predictions"]]})
se.3 <- lapply(res.out3, function(x){x[["standard_errors"]]})

#saveRDS(se.2, "MODEL/outlier_detection/full/full_se_2.rds")
```


```{r}
predictions <- c(readRDS("MODEL/outlier_detection/full/full_predictions_1.rds"), readRDS("MODEL/outlier_detection/full/full_predictions_2.rds"), readRDS("MODEL/outlier_detection/full/full_predictions_3.rds"))
standard_errors <- c(readRDS("MODEL/outlier_detection/full/full_se_1.rds"), readRDS("MODEL/outlier_detection/full/full_se_2.rds"), readRDS("MODEL/outlier_detection/full/full_se_3.rds"))

# remove the orgs with no outliers
candidates <- Filter(function(x) length(x) > 0, candidates)

cluster <- makeCluster(6)
registerDoParallel(cluster)

start.time <- Sys.time() #31 min
residuals <- foreach(ein = names(candidates), .packages = c("dplyr"), .verbose = TRUE) %dopar% {
      df.sub <- df |> filter(EIN2==ein)
      res <- (df.sub$LOG_REV - predictions[[ein]]) / standard_errors[[ein]] # standardized residuals
      res[which(df.sub$TAX_YEAR %in% candidates[[ein]])]
}
print(Sys.time() - start.time)
stopCluster(cl = cluster)

names(residuals) <- names(candidates)
saveRDS(residuals, "MODEL/outlier_detection/full/all_outlier_residuals.rds")
```


```{r}
result_df <- do.call(rbind, lapply(names(candidates), function(id) {
  data.frame(EIN = id, Value = candidates[[id]], STDRES = residuals[[id]])
}))

rownames(result_df) <- NULL
print(result_df)

result_df <- result_df |> mutate(SIGN = sign(STDRES), DIFF.abs = abs(STDRES - 3), DIFF.rel = (STDRES-3)/3) |> select(-DIFF)
result_df

saveRDS(result_df, "MODEL/outlier_detection/full/outlier_resids_DF.rds")
```

```{r}
my.palette <- c("#1796D2", "#D2D2D2", "#000000", "#FDC010", "#ED028B", "#55B748")
result_df |> ggplot() +
      geom_histogram(mapping = aes(x = Value, group = factor(SIGN), fill = factor(SIGN)), color = "black", bins = length(unique(all.years))) +
      scale_fill_manual(values = c("#1796D2",  "#FDC010")) +
      labs(x = "Year", title = "Outliers per Year")

result_df |> 
      filter(SIGN == -1) |> 
      ggplot() +
      geom_histogram(mapping = aes(x = Value), fill = "#1796D2", color = "black", bins = length(unique(all.years))) +
      labs(x = "Year", title = "Negative Outliers")

ggplot(df.stres, mapping = aes(x = factor(Value), y = STDRES, group = factor(Value))) +
      geom_boxplot() +
      theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
      labs(x = "Year", title = "Standardized Residuals of Outliers per Year") +
      ylim(-10, 10)
```

```{r}
titles <- list("1994", "2000", "2000", "2012 & 2014", "2021", "2011 & 2013")
names(titles) <- eins_to_check

for (ein in eins_to_check){
      p <- ggplot(df |> filter(EIN2==ein), aes(x = TAX_YEAR, y = TOT_REV)) +
            geom_line() +
            geom_point(size=3) +
            labs(title = paste(ein, titles[[ein]])) +
            scale_x_continuous(breaks = 1989:2021) +
            theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
      print(p)
}
```



# Latest Results

- 96 organizations, each has between 5 and 28 years worth of data (4 orgs per number of years)
- Constrained Nelder Mead with constraints $\nu \in (0.001, 3.5),\ \tau^2 \in (0,\infty)$ with 5 starting points based on centroids of $k$-means clustering of the 30-org test set
- When comparing with 15 Latin Hyper Cube samples (in terms of likelihoods), centroids is not always higher (though sometimes it is). However, the difference when LHS does better is tiny (like 0.001)
- Computation time: For 96 orgs, on 6 cores on my Macbook Pro took about 10s (total) to do the optimization

```{r, message = FALSE}
library(fields)
library(readr)
library(tidyverse, warn.conflicts = FALSE)
library(data.table)
library(dplyr, warn.conflicts = FALSE)
library(ggplot2)
library(tidyr)
library(mvtnorm)
library(pracma)
library(doParallel)
library(lhs)
source("SCRIPTS/outlier_detection_helper.R")

df <- as.data.table(read_csv("MODEL/small_test_96.csv", show_col_types = FALSE)) 

# center the data
df <- df |>
      group_by(EIN2) |>
      mutate(LOG_REV = LOG_REV - mean(LOG_REV)) |>
      ungroup()
```

```{r}
all_candidates <- readRDS("MODEL/outlier_detection/cNM_96_candidates.rds")
all_predictions <- readRDS("MODEL/outlier_detection/cNM_96_predictions.rds")
all_se <- readRDS("MODEL/outlier_detection/cNM_96_se.rds")
all.sigma.squared <- readRDS("MODEL/outlier_detection/cNM_96_sigmas.rds")

for (x in unique(sort(df$DATA_COUNT))){
      pList <- list()
      i <- 1
      outlier.flag <- FALSE
      for (ein in unique((df |> filter(DATA_COUNT == x))$EIN2) ){
            df.sub <- df |> filter(EIN2 == ein)
            pList[[i]] <- plot_true_vs_pred(df = df.sub,
                             ein = ein,
                             predictions = all_predictions[[ein]],
                             standard_errors = all_se[[ein]],
                             all_years = df.sub$YEAR + 1,
                             candidate_outliers = all_candidates[[ein]],
                             label = ein) + theme(legend.position = "bottom")
            if (length(all_candidates[[ein]]) > 0){
                  outlier.flag <- TRUE
                  leg <- get_plot_component(pList[[i]], "guide-box-bottom", return_all=TRUE)
            }
            i <- i+1
      }
      
      if (!outlier.flag) {leg <- get_plot_component(pList[[4]], "guide-box-bottom", return_all=TRUE)}
      
      p <- plot_grid(pList[[1]] + theme(legend.position = "none"), 
                     pList[[2]] + theme(legend.position = "none"), 
                     pList[[3]] + theme(legend.position = "none"), 
                     pList[[4]] + theme(legend.position = "none"), nrow = 2, ncol = 2)

      title <- ggdraw() + draw_label(paste("Number of data points:", x), fontface = 'bold', x = 0, hjust = 0) +
            theme(plot.margin = margin(l=10))
      print(plot_grid(title, p, leg, ncol = 1, rel_heights = c(0.1,1,0.1)))
}
```

# Results: Side by Side comparison
```{r, message=F}
library(fields)
library(readr)
library(tidyverse, warn.conflicts = FALSE)
library(data.table)
library(dplyr, warn.conflicts = FALSE)
library(ggplot2)
library(tidyr)
library(mvtnorm)
library(ParBayesianOptimization)
library(cowplot)
library(tibble)
source("SCRIPTS/outlier_detection_helper.R")
```

## Nelder-Mead (per org) versus Nelder-Mead (per org, year pair)
```{r}
df <- as.data.table(read_csv("small_test.csv", show_col_types = FALSE)) 

# center the data
df <- df |>
      group_by(EIN2) |>
      mutate(LOG_REV = LOG_REV - mean(LOG_REV)) |>
      ungroup()

#Load in results from Constrained Nelder-Mead per org ONLY
res.constrainNM <- readRDS("MODEL/outlier_detection/constrainNM_results.rds")
predictions.constrainNM <- readRDS("MODEL/outlier_detection/constrainNM_predictions.rds")
se.constrainNM <- readRDS("MODEL/outlier_detection/constrainNM_standard_errors.rds")
candidates.constrainNM <- readRDS("MODEL/outlier_detection/constrainNM_candidates.rds")

#Load in results from Constrained Nelder-Mead per org per year
res.par.constrainNM <- readRDS("MODEL/outlier_detection/par_constrainNM_results.rds")
predictions.par.constrainNM <- readRDS("MODEL/outlier_detection/par_constrainNM_predictions.rds")
se.par.constrainNM <- readRDS("MODEL/outlier_detection/par_constrainNM_standard_errors.rds")
candidates.par.constrainNM <- readRDS("MODEL/outlier_detection/par_constrainNM_candidates.rds")
```


```{r}
for (ein in unique(df$EIN2)){
      df.sub <- df |> filter(EIN2 == ein)
      zScore <- qt(0.95, df = length(df.sub$YEAR)-1)
      y_max <- max(c(predictions.par.constrainNM[[ein]] + (se.par.constrainNM[[ein]] * zScore), 
                     predictions.constrainNM[[ein]] + (se.constrainNM[[ein]] * zScore),
                     unlist(df.sub |> select(LOG_REV))))
      y_min <- min(c(predictions.par.constrainNM[[ein]] - (se.par.constrainNM[[ein]] * zScore), 
                     predictions.constrainNM[[ein]] - (se.constrainNM[[ein]] * zScore),
                     unlist(df.sub |> select(LOG_REV))))
      
      pConstrainNM <- plot_true_vs_pred(df, ein, predictions = predictions.constrainNM[[ein]], 
                             standard_errors = se.constrainNM[[ein]], 
                             all_years = df.sub$YEAR + 1, 
                             candidate_outliers = candidates.constrainNM[[ein]], 
                             y_lim = c(y_min, y_max),
                             round_to = 3) + theme(legend.position = "bottom")
      
      pConstrainNM.par <- plot_true_vs_pred(df, ein, predictions = predictions.par.constrainNM[[ein]], 
                             standard_errors = se.par.constrainNM[[ein]], 
                             all_years = df.sub$YEAR + 1, 
                             candidate_outliers = candidates.par.constrainNM[[ein]], 
                             y_lim = c(y_min, y_max)) + theme(legend.position = "bottom")

      # if neither have outliers or both have outliers, doesn't matter which legend we keep so keep first
      # if only one has outliers, keep the legend of the one with outliers
      if( (length(candidates.constrainNM[[ein]])==0 & length(candidates.par.constrainNM[[ein]])==0) | (length(candidates.constrainNM[[ein]])>0 & length(candidates.par.constrainNM[[ein]])>0)){
            leg <- get_plot_component(pConstrainNM, "guide-box-bottom", return_all=TRUE)
      } else if(length(candidates.constrainNM[[ein]]) > length(candidates.par.constrainNM[[ein]])){
            leg <- get_plot_component(pConstrainNM, "guide-box-bottom", return_all=TRUE)
      } else {
            leg <- get_plot_component(pConstrainNM.par, "guide-box-bottom", return_all=TRUE)
      }
      
      p <- plot_grid(pConstrainNM + theme(legend.position = "none"), 
                            pConstrainNM.par + theme(legend.position="none"), 
                            nrow = 1, labels = c('ORG', 'ORG-YEAR'))
      
      title <- ggdraw() + draw_label(ein, 
                                     fontface = 'bold', x = 0, hjust = 0) + theme(plot.margin = margin(l=10))
      print(plot_grid(title, p, leg, ncol = 1, rel_heights = c(0.1,1,0.1)))
}
```




## Grid versus Nelder-Mead, per org per year
```{r}
df <- as.data.table(read_csv("small_test.csv", show_col_types = FALSE)) 

# center the data
df <- df |>
      group_by(EIN2) |>
      mutate(LOG_REV = LOG_REV - mean(LOG_REV)) |>
      ungroup()

#Load in results from Grid Search
res.Grid <- readRDS("MODEL/outlier_detection/par_grid_results.rds")
predictions.Grid <- readRDS("MODEL/outlier_detection/par_grid_predictions.rds")
se.Grid <- readRDS("MODEL/outlier_detection/par_grid_standard_errors.rds")
candidates.Grid <- readRDS("MODEL/outlier_detection/par_grid_candidates.rds")

#Load in results from Constrained Nelder-Mead
res.constrainNM <- readRDS("MODEL/outlier_detection/par_constrainNM_results.rds")
predictions.constrainNM <- readRDS("MODEL/outlier_detection/par_constrainNM_predictions.rds")
se.constrainNM <- readRDS("MODEL/outlier_detection/par_constrainNM_standard_errors.rds")
candidates.constrainNM <- readRDS("MODEL/outlier_detection/par_constrainNM_candidates.rds")

# Create a df that shows the optimal parameters for each optimization algorithm per org
best_combos <- full_join(res.Grid, res.constrainNM, by = c("EIN", "year"), suffix = c(".grid", ".CNM"))

best_combos <- best_combos |> mutate(across(where(is.numeric), \(x) round(x, digits=4))) |> select(-trial, -nu.init, -nugg.init)
```

```{r}
head(best_combos |> select(-likelihood.grid, -likelihood.CNM, -sigma.squared.grid, -sigma.squared.CNM), 20)

print(paste("Out of ", nrow(best_combos), " org-year pairs, constrained Nelder-Mead got the higher likelihood (compared to grid search) for ", sum(best_combos$likelihood.grid <= best_combos$likelihood.CNM), " pairs.", sep = ""))
```

```{r}
mean_L.grid <- column_to_rownames(res.Grid |> group_by(EIN) |> summarize(MEAN = mean(likelihood)), var = "EIN")
mean_L.contrainNM <- column_to_rownames(res.constrainNM |> group_by(EIN) |> summarize(MEAN = mean(likelihood)), var = "EIN")

for (ein in unique(df$EIN2)){
      df.sub <- df |> filter(EIN2 == ein)
      zScore <- qt(0.95, df = length(df.sub$YEAR)-1)
      y_max <- max(c(predictions.constrainNM[[ein]] + (se.constrainNM[[ein]] * zScore), 
                     predictions.Grid[[ein]] + (se.Grid[[ein]] * zScore),
                     unlist(df.sub |> select(LOG_REV))))
      y_min <- min(c(predictions.constrainNM[[ein]] - (se.constrainNM[[ein]] * zScore), 
                     predictions.Grid[[ein]] - (se.Grid[[ein]] * zScore),
                     unlist(df.sub |> select(LOG_REV))))
      
      pConstrainNM <- plot_true_vs_pred(df, ein, predictions = predictions.constrainNM[[ein]], 
                             standard_errors = se.constrainNM[[ein]], 
                             all_years = df.sub$YEAR + 1, 
                             candidate_outliers = candidates.constrainNM[[ein]], 
                             y_lim = c(y_min, y_max),
                             round_to = 3) + theme(legend.position = "bottom")
      
      pGrid <- plot_true_vs_pred(df, ein, predictions = predictions.Grid[[ein]], 
                             standard_errors = se.Grid[[ein]], 
                             all_years = df.sub$YEAR + 1, 
                             candidate_outliers = candidates.Grid[[ein]], 
                             y_lim = c(y_min, y_max)) + theme(legend.position = "bottom")

      # if neither have outliers or both have outliers, doesn't matter which legend we keep so keep first
      # if only one has outliers, keep the legend of the one with outliers
      if( (length(candidates.constrainNM[[ein]])==0 & length(candidates.Grid[[ein]])==0) | (length(candidates.constrainNM[[ein]])>0 & length(candidates.Grid[[ein]])>0)){
            leg <- get_plot_component(pConstrainNM, "guide-box-bottom", return_all=TRUE)
      } else if(length(candidates.constrainNM[[ein]]) > length(candidates.Grid[[ein]])){
            leg <- get_plot_component(pConstrainNM, "guide-box-bottom", return_all=TRUE)
      } else {
            leg <- get_plot_component(pGrid, "guide-box-bottom", return_all=TRUE)
      }
      
      p <- plot_grid(pConstrainNM + theme(legend.position = "none"), 
                            pGrid + theme(legend.position="none"), 
                            nrow = 1, labels = c('NM', 'Grid'))
      
      title <- ggdraw() + draw_label(paste(ein, ", NM mean L() = ", round(mean_L.contrainNM[ein,], 3), ", Grid mean L() = ", round(mean_L.grid[ein,], 3), sep = ""), 
                                     fontface = 'bold', x = 0, hjust = 0) + theme(plot.margin = margin(l=10))
      print(plot_grid(title, p, leg, ncol = 1, rel_heights = c(0.1,1,0.1)))
}
```




## Grid versus Nelder-Mead - per year ONLY
```{r, eval = FALSE, echo = FALSE}
df <- as.data.table(read_csv("small_test.csv", show_col_types = FALSE)) 

# center the data
df <- df |>
      group_by(EIN2) |>
      mutate(LOG_REV = LOG_REV - mean(LOG_REV)) |>
      ungroup()

#Load in results from Grid Search
predictions.Grid <- readRDS("MODEL/outlier_detection/grid_predictions.rds")
se.Grid <- readRDS("MODEL/outlier_detection/grid_standard_errors.rds")
candidates.Grid <- readRDS("MODEL/outlier_detection/grid_candidates.rds")
best_pars.Grid <- readRDS("MODEL/outlier_detection/grid_best_params.rds")
max_L.Grid <- readRDS("MODEL/outlier_detection/grid_max_likelihoods.rds")

#Load in results from Constrained Nelder-Mead
res.constrainNM <- readRDS("MODEL/outlier_detection/constrainNM_results.rds")
predictions.constrainNM <- readRDS("MODEL/outlier_detection/constrainNM_predictions.rds")
se.constrainNM <- readRDS("MODEL/outlier_detection/constrainNM_standard_errors.rds")
candidates.constrainNM <- readRDS("MODEL/outlier_detection/constrainNM_candidates.rds")

# Create a df that shows the optimal parameters for each optimization algorithm per org
max_L.Grid <- rownames_to_column(as.data.frame(do.call(rbind, lapply(X = max_L.Grid, FUN = unlist))), var = "EIN")
best_pars.Grid <- rownames_to_column(best_pars.Grid, var = "EIN")

best_combos <- full_join(best_pars.Grid, res.constrainNM, by = "EIN", suffix = c(".grid", ".CNM"))

best_combos <- best_combos |> rename(all_of(c(sig.sqr.grid = "sigma.squared.grid", sig.sqr.CNM = "sigma.squared.CNM", nug.grid = "nugget.grid", nug.CNM = "nugget.CNM")))

best_combos <- best_combos |> mutate(across(where(is.numeric), round, digits=4)) |> select(-trial, -nu.init, -nugg.init, -likelihood)
```

```{r, eval = FALSE, echo = FALSE}
best_combos[,c(2,5,3,6,4,7)]
```

```{r, eval = FALSE, echo = FALSE}
rownames(max_L.Grid) <- max_L.Grid[,"EIN"]

for (ein in unique(df$EIN2)){
      zScore <- qt(0.95, df = length((df |> filter(EIN2 == ein))$YEAR)-1)
      y_max <- max(c(predictions.constrainNM[[ein]] + (se.constrainNM[[ein]] * zScore), 
                     predictions.Grid[[ein]] + (se.Grid[[ein]] * zScore),
                     unlist(df |> filter(EIN2==ein) |> select(LOG_REV))))
      y_min <- min(c(predictions.constrainNM[[ein]] - (se.constrainNM[[ein]] * zScore), 
                     predictions.Grid[[ein]] - (se.Grid[[ein]] * zScore),
                     unlist(df |> filter(EIN2==ein) |> select(LOG_REV))))
      
      pConstrainNM <- plot_true_vs_pred(df, ein, predictions = predictions.constrainNM[[ein]], 
                             standard_errors = se.constrainNM[[ein]], 
                             all_years = (df |> filter(EIN2 == ein))$YEAR + 1, 
                             candidate_outliers = candidates.constrainNM[[ein]], 
                             combo = res.constrainNM |> filter(EIN == ein) |> select(nu, nugget, sigma.squared),
                             y_lim = c(y_min, y_max),
                             round_to = 3) + theme(legend.position = "bottom", plot.title = element_text(hjust=1))
      
      pGrid <- plot_true_vs_pred(df, ein, predictions = predictions.Grid[[ein]], 
                             standard_errors = se.Grid[[ein]], 
                             all_years = (df |> filter(EIN2 == ein))$YEAR + 1, 
                             candidate_outliers = candidates.Grid[[ein]], 
                             combo = best_pars.Grid |> filter(EIN == ein),
                             y_lim = c(y_min, y_max)) + theme(legend.position = "bottom", plot.title = element_text(hjust=1))

      # if neither have outliers or both have outliers, doesn't matter which legend we keep so keep first
      # if only one has outliers, keep the legend of the one with outliers
      if( (length(candidates.constrainNM[[ein]])==0 & length(candidates.Grid[[ein]])==0) | (length(candidates.constrainNM[[ein]])>0 & length(candidates.Grid[[ein]])>0)){
            leg <- get_plot_component(pConstrainNM, "guide-box-bottom", return_all=TRUE)
      } else if(length(candidates.constrainNM[[ein]]) > length(candidates.Grid[[ein]])){
            leg <- get_plot_component(pConstrainNM, "guide-box-bottom", return_all=TRUE)
      } else {
            leg <- get_plot_component(pGrid, "guide-box-bottom", return_all=TRUE)
      }
      
      p <- plot_grid(pConstrainNM + theme(legend.position = "none"), 
                            pGrid + theme(legend.position="none"), 
                            nrow = 1, labels = c('NM', 'Grid'))
      
      title <- ggdraw() + draw_label(paste(ein, ", NM Likelihood = ", round(res.constrainNM[ein,]$likelihood, 3), ", Grid Likelihood = ", round(max_L.Grid[ein,]$V1, 3), sep = ""), 
                                     fontface = 'bold', x = 0, hjust = 0) + theme(plot.margin = margin(l=10))
      print(plot_grid(title, p, leg, ncol = 1, rel_heights = c(0.1,1,0.1)))
}
```



## Grid versus Bayes - per year ONLY
```{r, eval = FALSE, echo = FALSE}
df <- as.data.table(read_csv("small_test.csv", show_col_types = FALSE)) 

# center the data
df <- df |>
      group_by(EIN2) |>
      mutate(LOG_REV = LOG_REV - mean(LOG_REV)) |>
      ungroup()

#Load in results from Grid Search
predictions_grid <- readRDS("MODEL/outlier_detection/grid_predictions.rds")
se_grid <- readRDS("MODEL/outlier_detection/grid_standard_errors.rds")
candidates_grid <- readRDS("MODEL/outlier_detection/grid_candidates.rds")
best_params_grid <- readRDS("MODEL/outlier_detection/grid_best_params.rds")

# Load in results from Bayesian Optimization
predictions_bayes <- readRDS("MODEL/outlier_detection/bayesOpt_predictions.rds")
se_bayes <- readRDS("MODEL/outlier_detection/bayesOpt_standard_errors.rds")
candidates_bayes <- readRDS("MODEL/outlier_detection/bayesOpt_candidates.rds")
best_params_bayes <- readRDS("MODEL/outlier_detection/bayesOpt_best_params.rds")

# Create a df that shows the optimal parameters for each optimization algorithm per org
best_params_bayes <- rownames_to_column(as.data.frame(do.call(rbind, lapply(X = best_params_bayes, FUN = unlist))), var = "EIN") 
best_params_grid <- rownames_to_column(best_params_grid, var = "EIN")
best_combos <- full_join(best_params_grid, best_params_bayes, by = "EIN", suffix = c(".grid", ".bayes"))
best_combos <- best_combos[,c(1,2,5,3,6,4,7)] #reorder
best_combos <- best_combos |> rename(all_of(c(sig.sqr.grid = "sigma.squared.grid", sig.sqr.bayes = "sigma.squared.bayes", nug.grid = "nugget.grid", nug.bayes = "nugget.bayes")))
```


```{r, eval = FALSE, echo = FALSE, message=FALSE, warning=FALSE}
best_combos |> mutate(across(where(is.numeric), round, digits=3)) |> select(-EIN)
```

### Trouble-Shooting
```{r}
optInfo <- readRDS("MODEL/outlier_detection/bayesOpt_opt_info.rds")
max_likelihoods <- readRDS("MODEL/outlier_detection/grid_max_likelihoods.rds")
best_params_grid_raw <- readRDS("MODEL/outlier_detection/grid_best_params.rds")
best_params_bayes_raw <- readRDS("MODEL/outlier_detection/bayesOpt_best_params.rds")
max_likelihoods_bayesOpt <- list()

# check if BayesOpt consistently has bigger likelihoods than 
for (ein in unique(df$EIN2)){
      # Need to grab the row in scoreSummary corresponding to the "best parameters" determined by bayesOpt
      bScore <- (optInfo[[ein]]$scoreSummary |> filter(nu == best_params_bayes_raw[[ein]]$nu & nugget == best_params_bayes_raw[[ein]]$nugget & sigma.squared == best_params_bayes_raw[[ein]]$sigma.squared))
      max_likelihoods_bayesOpt[[ein]] <- bScore$Score
      # Print the score (likelihood) corresponding to "best BayesOpt parameters", the likelihood from "best GridOpt parameters
      print(paste(ein, bScore$Score, max_likelihoods[[ein]], (bScore$Score >= max_likelihoods[[ein]]), sep = ", "))
}
```

```{r}
# distance matrix of years
dist_mat <- dist(sort(unique(df$YEAR)), diag=TRUE, upper=TRUE)
dist_mat <- as.matrix(dist_mat)

# normalize
dist_mat <- (dist_mat - min(dist_mat)) / (max(dist_mat) - min(dist_mat))

rho <- 1

# check that likelihood functions works the same for both opt schemes 
for (ein in unique(df$EIN2)){
      combos <- optInfo[[ein]]$scoreSummary |> select(nu, nugget, sigma.squared, Score)
      combos$Likelihood <- apply(combos, 
                           MARGIN = 1, 
                           function(row) return(get_likelihood(row,
                                                dist_mat = dist_mat,
                                                rho = rho,
                                                all_years = (df |> filter(EIN2 == ein))$YEAR + 1,
                                                data = (df |> filter(EIN2 == ein))$LOG_REV))
                           )
      print(paste(ein, all(combos$Score == combos$Likelihood)))
}
```

```{r}
dat <- as.data.frame(list(Likelihood = c(unlist(max_likelihoods), unlist(max_likelihoods_bayesOpt)),
                          OptScheme = c(rep("Grid", 30), rep("Bayes", 30))))

dat |> ggplot(mapping = aes(x = Likelihood, color = OptScheme, fill = OptScheme)) +
      geom_histogram()

dat |> ggplot(mapping = aes(x = OptScheme, y = Likelihood, color = OptScheme)) + 
      geom_boxplot(outlier.colour="black", outlier.shape=16, outlier.size=2, notch=FALSE)
```

### Selected plots
Ranges (Bayesian Optimization)

- $\nu \in [0.025, 2.5]$
- $\tau^2 \in [0, 2.5]$
- $\sigma^2 \in [0.025, 1.5]$

Ranges (Grid Search Optimization)

- $\nu \in [0.05, 2.5]$
- $\tau^2 \in [0, 2]$
- $\sigma^2 \in [0.05, 0.95]$

```{r, eval = FALSE, echo = FALSE}
same <- c("EIN-04-2503758", "EIN-13-3547386", "EIN-15-6016932", "EIN-20-3754055", "EIN-20-5835134", "EIN-22-1487233", "EIN-23-7350663", "EIN-25-1891936", "EIN-27-3103886", "EIN-34-1521536", "EIN-38-2618245", "EIN-45-4079697", "EIN-46-1307863", "EIN-51-0179336", "EIN-64-0501136", "EIN-74-1396245", "EIN-76-0293955", "EIN-80-0011237", "EIN-94-1450438")
bayes_better <- c("EIN-13-3896558", "EIN-47-5626789")
grid_better <- c("EIN-63-0811078", "EIN-13-2720896", "EIN-14-1755337", "EIN-33-0183017", "EIN-36-4556466", "EIN-75-2897026")

for (ein in c("EIN-34-1521536", "EIN-51-0179336", "EIN-58-1708047", "EIN-77-0368378", "EIN-94-1450438", bayes_better, grid_better)){
      zScore <- qt(0.95, df = length((df |> filter(EIN2 == ein))$YEAR)-1)
      y_max <- max(c(predictions_bayes[[ein]] + (se_bayes[[ein]] * zScore), 
                     predictions_grid[[ein]] + (se_grid[[ein]] * zScore),
                     unlist(df |> filter(EIN2==ein) |> select(LOG_REV))))
      y_min <- min(c(predictions_bayes[[ein]] - (se_bayes[[ein]] * zScore), 
                     predictions_grid[[ein]] - (se_grid[[ein]] * zScore),
                     unlist(df |> filter(EIN2==ein) |> select(LOG_REV))))
      
      pBayes <- plot_true_vs_pred(df, ein, predictions = predictions_bayes[[ein]], 
                             standard_errors = se_bayes[[ein]], 
                             all_years = (df |> filter(EIN2 == ein))$YEAR + 1, 
                             candidate_outliers = candidates_bayes[[ein]], 
                             combo = best_params_bayes |> filter(EIN == ein),
                             y_lim = c(y_min, y_max),
                             label = paste("L = ", round(max_likelihoods_bayesOpt[[ein]], 2), ",", sep = "")) + 
            theme(legend.position = "bottom", plot.title = element_text(hjust=1))
      
      pGrid <- plot_true_vs_pred(df, ein, predictions = predictions_grid[[ein]], 
                             standard_errors = se_grid[[ein]], 
                             all_years = (df |> filter(EIN2 == ein))$YEAR + 1, 
                             candidate_outliers = candidates_grid[[ein]], 
                             combo = best_params_grid |> filter(EIN == ein),
                             y_lim = c(y_min, y_max),
                             label = paste("L = ", round(max_likelihoods[[ein]], 2), ",", sep = "")) + 
            theme(legend.position = "bottom", plot.title = element_text(hjust=1))

      # if neither have outliers or both have outliers, doesn't matter which legend we keep so keep first
      # if only one has outliers, keep the legend of the one with outliers
      if( (length(candidates_bayes[[ein]])==0 & length(candidates_grid[[ein]])==0) | (length(candidates_bayes[[ein]])>0 & length(candidates_grid[[ein]])>0)){
            leg <- get_plot_component(pBayes, "guide-box-bottom", return_all=TRUE)
      } else if(length(candidates_bayes[[ein]]) > length(candidates_grid[[ein]])){
            leg <- get_plot_component(pBayes, "guide-box-bottom", return_all=TRUE)
      } else {
            leg <- get_plot_component(pGrid, "guide-box-bottom", return_all=TRUE)
      }
      
      p <- plot_grid(pBayes + theme(legend.position = "none"), 
                            pGrid + theme(legend.position="none"), 
                            nrow = 1, labels = c('B', 'G'))
      
      title <- ggdraw() + draw_label(ein, fontface = 'bold', x = 0, hjust = 0) + theme(plot.margin = margin(l=10))
      print(plot_grid(title, p, leg, ncol = 1, rel_heights = c(0.1,1,0.1)))
}
```

### All plots
```{r, eval = FALSE, echo = FALSE}
for (ein in unique(df$EIN2)){
      zScore <- qt(0.95, df = length((df |> filter(EIN2 == ein))$YEAR)-1)
      y_max <- max(c(predictions_bayes[[ein]] + (se_bayes[[ein]] * zScore), 
                     predictions_grid[[ein]] + (se_grid[[ein]] * zScore),
                     unlist(df |> filter(EIN2==ein) |> select(LOG_REV))))
      y_min <- min(c(predictions_bayes[[ein]] - (se_bayes[[ein]] * zScore), 
                     predictions_grid[[ein]] - (se_grid[[ein]] * zScore),
                     unlist(df |> filter(EIN2==ein) |> select(LOG_REV))))
      
      pBayes <- plot_true_vs_pred(df, ein, predictions = predictions_bayes[[ein]], 
                             standard_errors = se_bayes[[ein]], 
                             all_years = (df |> filter(EIN2 == ein))$YEAR + 1, 
                             candidate_outliers = candidates_bayes[[ein]], 
                             combo = best_params_bayes |> filter(EIN == ein),
                             y_lim = c(y_min, y_max)) + theme(legend.position = "bottom", plot.title = element_text(hjust=1))
      
      pGrid <- plot_true_vs_pred(df, ein, predictions = predictions_grid[[ein]], 
                             standard_errors = se_grid[[ein]], 
                             all_years = (df |> filter(EIN2 == ein))$YEAR + 1, 
                             candidate_outliers = candidates_grid[[ein]], 
                             combo = best_params_grid |> filter(EIN == ein),
                             y_lim = c(y_min, y_max)) + theme(legend.position = "bottom", plot.title = element_text(hjust=1))

      # if neither have outliers or both have outliers, doesn't matter which legend we keep so keep first
      # if only one has outliers, keep the legend of the one with outliers
      if( (length(candidates_bayes[[ein]])==0 & length(candidates_grid[[ein]])==0) | (length(candidates_bayes[[ein]])>0 & length(candidates_grid[[ein]])>0)){
            leg <- get_plot_component(pBayes, "guide-box-bottom", return_all=TRUE)
      } else if(length(candidates_bayes[[ein]]) > length(candidates_grid[[ein]])){
            leg <- get_plot_component(pBayes, "guide-box-bottom", return_all=TRUE)
      } else {
            leg <- get_plot_component(pGrid, "guide-box-bottom", return_all=TRUE)
      }
      
      p <- plot_grid(pBayes + theme(legend.position = "none"), 
                            pGrid + theme(legend.position="none"), 
                            nrow = 1, labels = c('BayesOpt', 'Grid'))
      
      title <- ggdraw() + draw_label(ein, fontface = 'bold', x = 0, hjust = 0) + theme(plot.margin = margin(l=10))
      print(plot_grid(title, p, leg, ncol = 1, rel_heights = c(0.1,1,0.1)))
}
```



# Hyperparameter Tuning Code - one best set of params per org, but recompute sigma^2 each year
## Nelder-Mead
```{r, message = FALSE}
library(fields)
library(readr)
library(tidyverse, warn.conflicts = FALSE)
library(data.table)
library(dplyr, warn.conflicts = FALSE)
library(ggplot2)
library(tidyr)
library(mvtnorm)
library(pracma)
library(doParallel)
library(lhs)
source("SCRIPTS/outlier_detection_helper.R")
```

```{r}
df <- as.data.table(read_csv("small_test.csv", show_col_types = FALSE)) 

# center the data
df <- df |>
      group_by(EIN2) |>
      mutate(LOG_REV = LOG_REV - mean(LOG_REV)) |>
      ungroup()

# distance matrix of years
dist_mat <- as.matrix(dist(sort(unique(df$YEAR)), diag=TRUE, upper=TRUE))

# normalize
dist_mat <- (dist_mat - min(dist_mat)) / (max(dist_mat) - min(dist_mat))

# Set up ranges for Matern covariance matrix hyperparameters
rho <- 1

# All possible combinations of hyperparameters
#combos <- expand.grid(nu = seq(from = 0.05, to = 2.5, by = 0.1225), nugget = seq(from = 0, to = 2, by = 0.1)+0.001)
initial.conds <- readRDS("MODEL/outlier_detection/centroids5_30orgs.rds")$centers
```

```{r}
cluster <- makeCluster(6)
registerDoParallel(cluster)

# initial.conds <- randomLHS(10,2)
# initial.conds[, 1] <- 0.05 + initial.conds[, 1] * (2.5 - 0.05) # nu in [0.05,2.5)
# initial.conds[, 2] <- 0 + initial.conds[, 2] * (2 - 0) # nugget in [0,2]

# non-parallel: 1.09min , parallel (6): 14.01 s, parallel (6, 10 LHS): 10s, parallel (6, 5 centroids): 5s
# parallel (6, 5 centroids, nu upper bdd, chol): 4.3s, with solve: 4.5s

start.time <- Sys.time() 
res <- foreach(ein = unique(df$EIN2), .combine = 'rbind', .packages = c("dplyr", "fields", "mvtnorm")) %dopar% {
      df.sub <- filter(df, EIN2==ein)
      tst <- setNames(data.frame(matrix(ncol = 7, nrow = 0)), c("EIN", "nu.init", "nugg.init", "nu", "nugget", "likelihood", "trial"))
      likelihood_wrapper <- function(pars.vec){
            return(-1 * get_likelihood_sigma(row = pars.vec,
                                  dist_mat = dist_mat,
                                  rho = rho,
                                  all_years = df.sub$YEAR + 1,
                                  data = df.sub$LOG_REV))
      }
      
      for (i in 1:nrow(initial.conds)){
            res <- constrOptim(theta = initial.conds[i,], 
                               f = likelihood_wrapper,
                               grad = NULL,
                               ui = rbind(c(1,0),c(-1,0),c(0,1)), #rbind(c(1,0),c(-1,0),c(0,1))
                               ci = c(0.001,-3.5,0)) #c(0.001,-3.5, 0)
            tst[nrow(tst)+1,1] <- ein
            tst[nrow(tst),2:ncol(tst)] <- c(c(initial.conds[i,1], initial.conds[i,2], res$par[1], res$par[2], -1*res$value, i))
      }
      tst
}
print(Sys.time() - start.time)
stopCluster(cl = cluster) 
```


```{r}
max_L.Grid <- readRDS("MODEL/outlier_detection/grid_max_likelihoods.rds")
max_L.Grid <- rownames_to_column(as.data.frame(do.call(rbind, lapply(X = max_L.Grid, FUN = unlist))), var = "EIN")
max_L.constrainNM <- res |> group_by(EIN) |> summarise(MAX = max(likelihood)) 
full_join(max_L.Grid, max_L.constrainNM, by = "EIN", suffix = c(".grid", ".NM")) |> mutate(BIGGER = (V1 <= MAX))

res <- res |> inner_join(max_L.constrainNM, by = "EIN") |> filter(likelihood == MAX) |> select(-MAX)
```


```{r}
all.sigma.squared <- list()

all_predictions <- list()
all_candidates <- list()
all_se <- list()

mu_1 <- 0
# Looping over all organizations, 1.1 s without parallelization
start.time <- Sys.time()
for (ein in unique(df$EIN2)){
      df.sub <- filter(df, EIN2==ein)
      all_years <- df.sub$YEAR + 1 # all the years we have data for that org
      mu_2 <- numeric(nrow(df.sub) - 1) # all zeros
      
      predictions <- numeric(length(all_years)) # initialize
      standard_errors <- numeric(length(all_years)) # initialize
      
      sigs <- list()
      for(i in 1:length(all_years)){
            # Leave out i-th year
            log_revenue <- (df.sub |> filter(YEAR != all_years[i]-1))$LOG_REV
            
            # Generate Matern covariance matrix using "best" hyperparameters
            mat_cov <- Matern(d = dist_mat, 
                              smoothness = (res |> filter(EIN == ein))$nu, 
                              range = rho, 
                              phi = 1) + diag((res |> filter(EIN == ein))$nugget, dim(dist_mat)[1])
            
            sigma.squared <- (1/length(log_revenue)) * (log_revenue %*% chol2inv(chol(mat_cov[all_years[-i], all_years[-i]])) %*% log_revenue)[1,1]
            mat_cov <- sigma.squared * mat_cov
            
            sigs <- c(sigs, sigma.squared)
            
            SIGMA.11 <- mat_cov[all_years[i], all_years[i]]
            SIGMA.22.inv <- chol2inv(chol(mat_cov[all_years[-i], all_years[-i]]))
            SIGMA.12 <- mat_cov[all_years[i], all_years[-i], drop = FALSE]
            
            predictions[i] <- mu_1 + (SIGMA.12 %*% SIGMA.22.inv %*% (log_revenue - mu_2)) #mu_bar
            standard_errors[i] <- sqrt(as.numeric(SIGMA.11 - (SIGMA.12 %*% SIGMA.22.inv %*% t(SIGMA.12))))
      }
      all.sigma.squared[[ein]] <- sigs
      
      residuals <- abs(df.sub$LOG_REV - predictions) / standard_errors # standardized residuals
      
      all_predictions[[ein]] <- predictions
      all_se[[ein]] <- standard_errors
      all_candidates[[ein]] <-  all_years[which(residuals > 3)] - 1 + 1989
}

print(Sys.time() - start.time)
```

```{r}
for (ein in unique(df$EIN2)){
      df.sub <- filter(df, EIN2==ein)
      p <- plot_true_vs_pred(df = df.sub,
                             ein = ein,
                             predictions = all_predictions[[ein]],
                             standard_errors = all_se[[ein]],
                             all_years = df.sub$YEAR + 1,
                             candidate_outliers = all_candidates[[ein]],
                             label = ein)
      print(p)
}
```


## Slightly larger dataset (96)
```{r, message = FALSE}
library(fields)
library(readr)
library(tidyverse, warn.conflicts = FALSE)
library(data.table)
library(dplyr, warn.conflicts = FALSE)
library(ggplot2)
library(tidyr)
library(mvtnorm)
library(pracma)
library(doParallel)
library(lhs)
source("SCRIPTS/outlier_detection_helper.R")
```


```{r}
df <- as.data.table(read_csv("MODEL/small_test_96.csv", show_col_types = FALSE)) 

# center the data
df <- df |>
      group_by(EIN2) |>
      mutate(LOG_REV = LOG_REV - mean(LOG_REV)) |>
      ungroup()

# distance matrix of years
dist_mat <- as.matrix(dist(sort(unique(df$YEAR)), diag=TRUE, upper=TRUE))

# normalize
dist_mat <- (dist_mat - min(dist_mat)) / (max(dist_mat) - min(dist_mat))

# Set up ranges for Matern covariance matrix hyperparameters
rho <- 1

# All possible combinations of hyperparameters
#combos <- expand.grid(nu = seq(from = 0.05, to = 2.5, by = 0.1225), nugget = seq(from = 0, to = 2, by = 0.1)+0.001)
initial.conds <- readRDS("MODEL/outlier_detection/centroids5_30orgs.rds")$centers
```


```{r}
cluster <- makeCluster(6)
registerDoParallel(cluster)

# 102: 17.5 secs (Google Meet was open), 14s (Google Meet not open)
# 96:  10.2 secs
start.time <- Sys.time() 
res.centroids <- foreach(ein = unique(df$EIN2), .combine = 'rbind', .packages = c("dplyr", "fields", "mvtnorm")) %dopar% {
      df.sub <- filter(df, EIN2==ein)
      tst <- setNames(data.frame(matrix(ncol = 7, nrow = 0)), c("EIN", "nu.init", "nugg.init", "nu", "nugget", "likelihood", "trial"))
      likelihood_wrapper <- function(pars.vec){
            return(-1 * get_likelihood_sigma(row = pars.vec,
                                  dist_mat = dist_mat,
                                  rho = rho,
                                  all_years = df.sub$YEAR + 1,
                                  data = df.sub$LOG_REV))
      }
      
      for (i in 1:nrow(initial.conds)){
            res <- constrOptim(theta = initial.conds[i,], 
                               f = likelihood_wrapper,
                               grad = NULL,
                               ui = rbind(c(1,0),c(-1,0),c(0,1)), #rbind(c(1,0),c(-1,0),c(0,1))
                               ci = c(0.001,-3.5,0)) #c(0.001,-3.5, 0)
            tst[nrow(tst)+1,1] <- ein
            tst[nrow(tst),2:ncol(tst)] <- c(c(initial.conds[i,1], initial.conds[i,2], res$par[1], res$par[2], -1*res$value, i))
      }
      tst[which.max(tst$likelihood),]
}
print(Sys.time() - start.time)
stopCluster(cl = cluster)
```


### Training the GPs and Detecting the Outliers
```{r}
res <- readRDS("MODEL/outlier_detection/cNM_96_results.rds")

all.sigma.squared <- list()
all_predictions <- list()
all_candidates <- list()
all_se <- list()

mu_1 <- 0
# Looping over all organizations, 3 s without parallelization
start.time <- Sys.time()
for (ein in unique(df$EIN2)){
      df.sub <- filter(df, EIN2==ein)
      all_years <- df.sub$YEAR + 1 # all the years we have data for that org
      mu_2 <- numeric(nrow(df.sub) - 1) # all zeros
      
      predictions <- numeric(length(all_years)) # initialize
      standard_errors <- numeric(length(all_years)) # initialize
      
      sigs <- list()
      for(i in 1:length(all_years)){
            # Leave out i-th year
            log_revenue <- (df.sub |> filter(YEAR != all_years[i]-1))$LOG_REV
            
            # Generate Matern covariance matrix using "best" hyperparameters
            mat_cov <- Matern(d = dist_mat, 
                              smoothness = (res |> filter(EIN == ein))$nu, 
                              range = rho, 
                              phi = 1) + diag((res |> filter(EIN == ein))$nugget, dim(dist_mat)[1])
            
            sigma.squared <- (1/length(log_revenue)) * (log_revenue %*% chol2inv(chol(mat_cov[all_years[-i], all_years[-i]])) %*% log_revenue)[1,1]
            mat_cov <- sigma.squared * mat_cov
            
            sigs <- c(sigs, sigma.squared)
            
            SIGMA.11 <- mat_cov[all_years[i], all_years[i]]
            SIGMA.22.inv <- chol2inv(chol(mat_cov[all_years[-i], all_years[-i]]))
            SIGMA.12 <- mat_cov[all_years[i], all_years[-i], drop = FALSE]
            
            predictions[i] <- mu_1 + (SIGMA.12 %*% SIGMA.22.inv %*% (log_revenue - mu_2)) #mu_bar
            standard_errors[i] <- sqrt(as.numeric(SIGMA.11 - (SIGMA.12 %*% SIGMA.22.inv %*% t(SIGMA.12))))
      }
      all.sigma.squared[[ein]] <- sigs
      
      residuals <- abs(df.sub$LOG_REV - predictions) / standard_errors # standardized residuals
      
      all_predictions[[ein]] <- predictions
      all_se[[ein]] <- standard_errors
      all_candidates[[ein]] <-  all_years[which(residuals > 3)] - 1 + 1989
}

print(Sys.time() - start.time)

saveRDS(all_candidates, "MODEL/outlier_detection/cNM_96_candidates.rds")
saveRDS(all_predictions, "MODEL/outlier_detection/cNM_96_predictions.rds")
saveRDS(all_se, "MODEL/outlier_detection/cNM_96_se.rds")
saveRDS(all.sigma.squared, "MODEL/outlier_detection/cNM_96_sigmas.rds")
```


```{r}
for (x in unique(sort(df$DATA_COUNT))){
      pList <- list()
      i <- 1
      outlier.flag <- FALSE
      for (ein in unique((df |> filter(DATA_COUNT == x))$EIN2) ){
            df.sub <- df |> filter(EIN2 == ein)
            pList[[i]] <- plot_true_vs_pred(df = df.sub,
                             ein = ein,
                             predictions = all_predictions[[ein]],
                             standard_errors = all_se[[ein]],
                             all_years = df.sub$YEAR + 1,
                             candidate_outliers = all_candidates[[ein]],
                             label = ein) + theme(legend.position = "bottom")
            if (length(all_candidates[[ein]]) > 0){
                  outlier.flag <- TRUE
                  leg <- get_plot_component(pList[[i]], "guide-box-bottom", return_all=TRUE)
            }
            i <- i+1
      }
      
      if (!outlier.flag) {leg <- get_plot_component(pList[[4]], "guide-box-bottom", return_all=TRUE)}
      
      p <- plot_grid(pList[[1]] + theme(legend.position = "none"), 
                     pList[[2]] + theme(legend.position = "none"), 
                     pList[[3]] + theme(legend.position = "none"), 
                     pList[[4]] + theme(legend.position = "none"), nrow = 2, ncol = 2)

      title <- ggdraw() + draw_label(paste("Number of data points:", x), fontface = 'bold', x = 0, hjust = 0) +
            theme(plot.margin = margin(l=10))
      print(plot_grid(title, p, leg, ncol = 1, rel_heights = c(0.1,1,0.1)))
}
```





## Even larger (414)
```{r, message = FALSE}
library(fields)
library(readr)
library(tidyverse, warn.conflicts = FALSE)
library(data.table)
library(dplyr, warn.conflicts = FALSE)
library(ggplot2)
library(tidyr)
library(mvtnorm)
library(pracma)
library(doParallel)
library(lhs)
source("SCRIPTS/outlier_detection_helper.R")
```


```{r}
df <- as.data.table(read_csv("MODEL/small_test_414.csv", show_col_types = FALSE)) 

# center the data
df <- df |>
      group_by(EIN2) |>
      mutate(LOG_REV = LOG_REV - mean(LOG_REV)) |>
      ungroup()

# distance matrix of years
dist_mat <- as.matrix(dist(sort(unique(df$YEAR)), diag=TRUE, upper=TRUE))

# normalize
dist_mat <- (dist_mat - min(dist_mat)) / (max(dist_mat) - min(dist_mat))

# Set up ranges for Matern covariance matrix hyperparameters
rho <- 1

# All possible combinations of hyperparameters
#combos <- expand.grid(nu = seq(from = 0.05, to = 2.5, by = 0.1225), nugget = seq(from = 0, to = 2, by = 0.1)+0.001)
initial.conds <- readRDS("MODEL/outlier_detection/centroids5_96orgs.rds")$centers
```


```{r}
cluster <- makeCluster(6)
registerDoParallel(cluster)

# 414: 48s
start.time <- Sys.time() 
res <- foreach(ein = unique(df$EIN2), .combine = 'rbind', .packages = c("dplyr", "fields", "mvtnorm")) %dopar% {
      df.sub <- filter(df, EIN2==ein)
      tst <- setNames(data.frame(matrix(ncol = 5, nrow = 0)), c("EIN", "nu", "nugget", "likelihood", "trial"))
      likelihood_wrapper <- function(pars.vec){
            return(-1 * get_likelihood_sigma(row = pars.vec,
                                  dist_mat = dist_mat,
                                  rho = rho,
                                  all_years = df.sub$YEAR + 1,
                                  data = df.sub$LOG_REV))
      }
      
      for (i in 1:nrow(initial.conds)){
            res <- constrOptim(theta = initial.conds[i,], 
                               f = likelihood_wrapper,
                               grad = NULL,
                               ui = rbind(c(1,0),c(-1,0),c(0,1)), #rbind(c(1,0),c(-1,0),c(0,1))
                               ci = c(0.001,-3.5,0)) #c(0.001,-3.5, 0)
            tst[nrow(tst)+1,1] <- ein
            tst[nrow(tst),2:ncol(tst)] <- c(c(res$par[1], res$par[2], -1*res$value, i))
      }
      tst[which.max(tst$likelihood),]
}
print(Sys.time() - start.time)
stopCluster(cl = cluster)

#saveRDS(res, "MODEL/outlier_detection/cNM_414_results.rds")
```


```{r}
                                                                                                    
cl <- kmeans(res |> select(nu,nugget), 5, iter.max = 20, nstart = 3)
cl$size
cl$centers
initial.conds

saveRDS(cl, "MODEL/outlier_detection/centroids5_414orgs.rds")
```


```{r}
all.sigma.squared <- list()
all_predictions <- list()
all_candidates <- list()
all_se <- list()

mu_1 <- 0
# Looping over all organizations, 3 s without parallelization
start.time <- Sys.time()
for (ein in unique(df$EIN2)){
      df.sub <- filter(df, EIN2==ein)
      all_years <- df.sub$YEAR + 1 # all the years we have data for that org
      mu_2 <- numeric(nrow(df.sub) - 1) # all zeros
      
      predictions <- numeric(length(all_years)) # initialize
      standard_errors <- numeric(length(all_years)) # initialize
      
      sigs <- list()
      for(i in 1:length(all_years)){
            # Leave out i-th year
            log_revenue <- (df.sub |> filter(YEAR != all_years[i]-1))$LOG_REV
            
            # Generate Matern covariance matrix using "best" hyperparameters
            mat_cov <- Matern(d = dist_mat, 
                              smoothness = (res |> filter(EIN == ein))$nu, 
                              range = rho, 
                              phi = 1) + diag((res |> filter(EIN == ein))$nugget, dim(dist_mat)[1])
            
            sigma.squared <- (1/length(log_revenue)) * (log_revenue %*% chol2inv(chol(mat_cov[all_years[-i], all_years[-i]])) %*% log_revenue)[1,1]
            mat_cov <- sigma.squared * mat_cov
            
            sigs <- c(sigs, sigma.squared)
            
            SIGMA.11 <- mat_cov[all_years[i], all_years[i]]
            SIGMA.22.inv <- chol2inv(chol(mat_cov[all_years[-i], all_years[-i]]))
            SIGMA.12 <- mat_cov[all_years[i], all_years[-i], drop = FALSE]
            
            predictions[i] <- mu_1 + (SIGMA.12 %*% SIGMA.22.inv %*% (log_revenue - mu_2)) #mu_bar
            standard_errors[i] <- sqrt(as.numeric(SIGMA.11 - (SIGMA.12 %*% SIGMA.22.inv %*% t(SIGMA.12))))
      }
      all.sigma.squared[[ein]] <- sigs
      
      residuals <- abs(df.sub$LOG_REV - predictions) / standard_errors # standardized residuals
      
      all_predictions[[ein]] <- predictions
      all_se[[ein]] <- standard_errors
      all_candidates[[ein]] <-  all_years[which(residuals > 3)] - 1 + 1989
}

print(Sys.time() - start.time)
```

# Hyperparameter Tuning Code - one best set of params per org per year
## Nelder Mead
```{r, message = FALSE}
library(fields)
library(readr)
library(tidyverse, warn.conflicts = FALSE)
library(data.table)
library(dplyr, warn.conflicts = FALSE)
library(ggplot2)
library(tidyr)
library(mvtnorm)
library(pracma)
library(doParallel)
source("SCRIPTS/outlier_detection_helper.R")
```

```{r}
df <- as.data.table(read_csv("small_test.csv", show_col_types = FALSE)) 

# center the data
df <- df |>
      group_by(EIN2) |>
      mutate(LOG_REV = LOG_REV - mean(LOG_REV)) |>
      ungroup()

# distance matrix of years
dist_mat <- dist(sort(unique(df$YEAR)), diag=TRUE, upper=TRUE)
dist_mat <- as.matrix(dist_mat)

# normalize
dist_mat <- (dist_mat - min(dist_mat)) / (max(dist_mat) - min(dist_mat))

# Set up ranges for Matern covariance matrix hyperparameters
rho <- 1

# All possible combinations of hyperparameters
combos <- expand.grid(nu = seq(from = 0.05, to = 2.5, by = 0.1225), 
                      nugget = seq(from = 0, to = 2, by = 0.1)+0.001)
```

```{r}
# Register cluster
cluster <- makeCluster(6)
registerDoParallel(cluster)
clusterExport(cluster,c('df'))
clusterEvalQ(cluster,expr= {
      source("SCRIPTS/outlier_detection_helper.R")
})

start.time <- Sys.time()
max_L.constrainNM.par <- foreach(ein = unique(df$EIN2), .combine = 'rbind', .packages = c("dplyr", "fields", "mvtnorm")) %dopar% {
      df.sub <- filter(df, EIN2==ein)
      all_years <- df.sub$YEAR + 1 # all the years we have data for that org
      
      tst <- setNames(data.frame(matrix(ncol = 8, nrow = 0)), c("EIN", "year", "nu.init", "nugg.init", "nu", "nugget", "likelihood", "trial"))
      for(i in 1:length(all_years)){ # Leave out i-th year
            likelihood_wrapper <- function(pars.vec){
                  return(-1 * get_likelihood(row = pars.vec,
                                        dist_mat = dist_mat,
                                        rho = rho,
                                        all_years = all_years[-i],
                                        data = (df.sub |> filter(YEAR != all_years[i]-1))$LOG_REV,
                                        compute.sigma = TRUE))
            }
            initial.conds <- combos[sample(nrow(combos), 15),]
            for (j in 1:nrow(initial.conds)){
                  res <- constrOptim(theta = as.numeric(as.vector(initial.conds[j,])), 
                                     f = likelihood_wrapper,
                                     grad = NULL,
                                     ui = cbind(c(1,0),c(0,1)),
                                     ci = c(0.001,0))
                  tst[nrow(tst)+1,1] <- ein
                  tst[nrow(tst), 2:ncol(tst)] <- c(all_years[i]-1, initial.conds[j,1], initial.conds[j,2], res$par[1], res$par[2], -1*res$value, j)
            }
      }
      tst
}
print(Sys.time() - start.time) # ~10 min
stopCluster(cl = cluster) 
```

```{r}
maxes.constrainNM.par <- max_L.constrainNM.par |> group_by(EIN, year) |> summarise(MAX = max(likelihood)) 

saveRDS(max_L.constrainNM.par |> inner_join(maxes.constrainNM.par, by = c("EIN", "year")) |> filter(likelihood == MAX) |> select(-MAX), 
        "MODEL/outlier_detection/par_constrainNM_results.rds")
```

```{r}
res <- readRDS("MODEL/outlier_detection/par_constrainNM_results.rds")
res <- res |> mutate(sigma.squared = 0)

all_predictions = list()
all_candidates = list()
all_se = list()

mu_1 <- 0
# Looping over all organizations
start.time <- Sys.time()
for (ein in unique(df$EIN2)){
      df.sub <- filter(df, EIN2==ein)
      all_years <- df.sub$YEAR + 1 # all the years we have data for that org
      mu_2 <- numeric(nrow(df.sub) - 1) # all zeros
      
      predictions <- numeric(length(all_years)) # initialize
      standard_errors <- numeric(length(all_years)) # initialize
      
      for(i in 1:length(all_years)){
            # Leave out i-th year
            log_revenue <- (df.sub |> filter(YEAR != all_years[i]-1))$LOG_REV
            
            # Generate Matern covariance matrix using "best" hyperparameters
            mat_cov <- Matern(d = dist_mat, 
                              smoothness = (res |> filter(EIN == ein, year == all_years[i]-1))$nu, 
                              range = rho, 
                              phi = 1) + diag((res |> filter(EIN == ein, year == all_years[i]-1))$nugget, dim(dist_mat)[1])
            
            sigma.squared <- (1/length(log_revenue)) * (log_revenue %*% solve(mat_cov[all_years[-i], all_years[-i]]) %*% log_revenue)[1,1]
            mat_cov <- sigma.squared * mat_cov
            
            res[(res$EIN == ein & res$year == all_years[i]-1),]$sigma.squared <- sigma.squared
            
            SIGMA.11 <- mat_cov[all_years[i], all_years[i]]
            SIGMA.22.inv <- solve(mat_cov[all_years[-i], all_years[-i]])
            SIGMA.12 <- mat_cov[all_years[i], all_years[-i], drop = FALSE]
            
            predictions[i] <- mu_1 + (SIGMA.12 %*% SIGMA.22.inv %*% (log_revenue - mu_2)) #mu_bar
            standard_errors[i] <- sqrt(as.numeric(SIGMA.11 - (SIGMA.12 %*% SIGMA.22.inv %*% t(SIGMA.12))))
      }
      
      residuals <- abs(df.sub$LOG_REV - predictions) / standard_errors # standardized residuals
      
      all_predictions[[ein]] <- predictions
      all_se[[ein]] <- standard_errors
      all_candidates[[ein]] <-  all_years[which(residuals > 3)] - 1 + 1989
      
      p <- plot_true_vs_pred(df = df, 
                             ein = ein, 
                             predictions = predictions, 
                             standard_errors = standard_errors, 
                             all_years = all_years, 
                             candidate_outliers = all_candidates[ein], 
                             label = ein)
      print(p)
}

print(Sys.time() - start.time)
```

### Non parallel version

```{r}
max_L.constrainNM <- setNames(data.frame(matrix(ncol = 8, nrow = 0)), c("EIN", "year", "nu.init", "nugg.init", "nu", "nugget", "likelihood", "trial"))

start.time <- Sys.time()
for (ein in unique(df$EIN2)){ #~40min
      print(ein)
      df.sub <- filter(df, EIN2==ein)
      all_years <- df.sub$YEAR + 1 # all the years we have data for that org
      
      for(i in 1:length(all_years)){ # Leave out i-th year
            likelihood_wrapper <- function(pars.vec){
                  return(-1 * get_likelihood(row = pars.vec,
                                        dist_mat = dist_mat,
                                        rho = rho,
                                        all_years = all_years[-i],
                                        data = (df.sub |> filter(YEAR != all_years[i]-1))$LOG_REV,
                                        compute.sigma = TRUE))
            }
            initial.conds <- combos[sample(nrow(combos), 15),]
            for (j in 1:nrow(initial.conds)){
                  res <- constrOptim(theta = as.numeric(as.vector(initial.conds[j,])), 
                                     f = likelihood_wrapper,
                                     grad = NULL,
                                     ui = cbind(c(1,0),c(0,1)),
                                     ci = c(0.001,0))
                  max_L.constrainNM[nrow(max_L.constrainNM)+1,1] <- ein
                  max_L.constrainNM[nrow(max_L.constrainNM),2:ncol(max_L.constrainNM)] <- c(all_years[i]-1, initial.conds[j,1], initial.conds[j,2], res$par[1], res$par[2], -1*res$value, j)
            }
      }
}
print(Sys.time() - start.time)
```


## Grid Search
```{r, message=F, echo = FALSE, eval = FALSE}
library(fields)
library(readr)
library(tidyverse, warn.conflicts = FALSE)
library(data.table)
library(dplyr, warn.conflicts = FALSE)
library(ggplot2)
library(tidyr)
library(mvtnorm)
library(doParallel)
source("SCRIPTS/outlier_detection_helper.R")
```

```{r, echo = TRUE, eval = FALSE}
df <- as.data.table(read_csv("small_test.csv", show_col_types = FALSE)) 

# center the data
df <- df |>
      group_by(EIN2) |>
      mutate(LOG_REV = LOG_REV - mean(LOG_REV)) |>
      ungroup()

# distance matrix of years
dist_mat <- as.matrix(dist(sort(unique(df$YEAR)), diag=TRUE, upper=TRUE))

# normalize
dist_mat <- (dist_mat - min(dist_mat)) / (max(dist_mat) - min(dist_mat))

# Set up ranges for Matern covariance matrix hyperparameters
rho <- 1
# All possible combinations of hyperparameters
combos <- expand.grid(nu = seq(from = 0.025, to = 2.5, by = 0.165), 
                      nugget = seq(from = 0, to = 2.5, by = 0.1))
```

```{r}
# Register cluster
cluster <- makeCluster(6)
registerDoParallel(cluster)
#clusterExport(cluster,c('df', 'combos'))
clusterEvalQ(cluster,expr= {
      source("SCRIPTS/outlier_detection_helper.R")
})

start.time <- Sys.time() # .combine = 'rbind'
likelihoods.grid.par <- foreach(ein = unique(df$EIN2), .combine = 'rbind', .packages = c("dplyr", "fields", "mvtnorm")) %dopar% {
      df.sub <- filter(df, EIN2==ein)
      all_years <- df.sub$YEAR + 1 # all the years we have data for that org
      tst <- setNames(data.frame(matrix(ncol = 5, nrow = 0)), c("EIN", "year", "nu", "nugget", "likelihood")) # empty data.frame

      for(i in 1:length(all_years)){ # Leave out i-th year
            likelihoods <- apply(combos, 
                           MARGIN = 1, 
                           function(row) return(get_likelihood(row,
                                          dist_mat = dist_mat,
                                          rho = rho,
                                          all_years = all_years[-i],
                                          data = (df.sub |> filter(YEAR != all_years[i]-1))$LOG_REV,
                                          compute.sigma = TRUE)))
      
            tst <- rbind(tst, as.data.frame(list(EIN = rep(ein, length(likelihoods)),
                         year = rep(all_years[i]-1, length(likelihoods)),
                         nu = combos$nu,
                         nugget = combos$nugget,
                         likelihood = likelihoods)))     
      }
      tst
}

print(Sys.time() - start.time) # time
stopCluster(cl = cluster) 


#best_combos <- combos[as.vector(unlist(max_likelihoods_idx)),]
#row.names(best_combos) <- names(max_likelihoods_idx)

#best_combos
```

```{r}
maxes.grid.par <- likelihoods.grid.par |> group_by(EIN, year) |> summarise(MAX = max(likelihood)) 

saveRDS(likelihoods.grid.par |> inner_join(maxes.grid.par, by = c("EIN", "year")) |> filter(likelihood == MAX) |> select(-MAX), 
        "MODEL/outlier_detection/par_grid_results.rds")
```

```{r}
res <- readRDS("MODEL/outlier_detection/par_grid_results.rds")
res <- res |> mutate(sigma.squared = 0)

all_predictions = list()
all_candidates = list()
all_se = list()

mu_1 <- 0
# Looping over all organizations
start.time <- Sys.time()
for (ein in unique(df$EIN2)){
      df.sub <- filter(df, EIN2==ein)
      all_years <- df.sub$YEAR + 1 # all the years we have data for that org
      mu_2 <- numeric(nrow(df.sub) - 1) # all zeros
      
      predictions <- numeric(length(all_years)) # initialize
      standard_errors <- numeric(length(all_years)) # initialize
      
      for(i in 1:length(all_years)){
            # Leave out i-th year
            log_revenue <- (df.sub |> filter(YEAR != all_years[i]-1))$LOG_REV
            
            # Generate Matern covariance matrix using "best" hyperparameters
            mat_cov <- Matern(d = dist_mat, 
                              smoothness = (res |> filter(EIN == ein, year == all_years[i]-1))$nu, 
                              range = rho, 
                              phi = 1) + diag((res |> filter(EIN == ein, year == all_years[i]-1))$nugget, dim(dist_mat)[1])
            
            sigma.squared <- (1/length(log_revenue)) * (log_revenue %*% solve(mat_cov[all_years[-i], all_years[-i]]) %*% log_revenue)[1,1]
            mat_cov <- sigma.squared * mat_cov
            
            res[(res$EIN == ein & res$year == all_years[i]-1),]$sigma.squared <- sigma.squared
            
            SIGMA.11 <- mat_cov[all_years[i], all_years[i]]
            SIGMA.22.inv <- solve(mat_cov[all_years[-i], all_years[-i]])
            SIGMA.12 <- mat_cov[all_years[i], all_years[-i], drop = FALSE]
            
            predictions[i] <- mu_1 + (SIGMA.12 %*% SIGMA.22.inv %*% (log_revenue - mu_2)) #mu_bar
            standard_errors[i] <- sqrt(as.numeric(SIGMA.11 - (SIGMA.12 %*% SIGMA.22.inv %*% t(SIGMA.12))))
      }
      
      residuals <- abs(df.sub$LOG_REV - predictions) / standard_errors # standardized residuals
      
      all_predictions[[ein]] <- predictions
      all_se[[ein]] <- standard_errors
      all_candidates[[ein]] <-  all_years[which(residuals > 3)] - 1 + 1989
      
      p <- plot_true_vs_pred(df = df, 
                             ein = ein, 
                             predictions = predictions, 
                             standard_errors = standard_errors, 
                             all_years = all_years, 
                             candidate_outliers = all_candidates[ein], 
                             label = ein)
      print(p)
}

print(Sys.time() - start.time)
```

```{r}
saveRDS(res, "MODEL/outlier_detection/par_grid_results.rds")
saveRDS(all_predictions, "MODEL/outlier_detection/par_grid_predictions.rds")
saveRDS(all_se, "MODEL/outlier_detection/par_grid_standard_errors.rds")
saveRDS(all_candidates, "MODEL/outlier_detection/par_grid_candidates.rds")
```




# Hyperparameter Tuning Code - one best set of params per org
## Nelder Mead
```{r, message = FALSE}
library(fields)
library(readr)
library(tidyverse, warn.conflicts = FALSE)
library(data.table)
library(dplyr, warn.conflicts = FALSE)
library(ggplot2)
library(tidyr)
library(mvtnorm)
library(pracma)
source("SCRIPTS/outlier_detection_helper.R")
```

```{r}
df <- as.data.table(read_csv("small_test.csv", show_col_types = FALSE)) 

# center the data
df <- df |>
      group_by(EIN2) |>
      mutate(LOG_REV = LOG_REV - mean(LOG_REV)) |>
      ungroup()

# distance matrix of years
dist_mat <- dist(sort(unique(df$YEAR)), diag=TRUE, upper=TRUE)
dist_mat <- as.matrix(dist_mat)

# normalize
dist_mat <- (dist_mat - min(dist_mat)) / (max(dist_mat) - min(dist_mat))

# Set up ranges for Matern covariance matrix hyperparameters
rho <- 1

# All possible combinations of hyperparameters
combos <- expand.grid(nu = seq(from = 0.05, to = 2.5, by = 0.1225), 
                      nugget = seq(from = 0, to = 2, by = 0.1)+0.001)
```

```{r}
max_L.constrainNM <- setNames(data.frame(matrix(ncol = 7, nrow = 0)), c("EIN", "nu.init", "nugg.init", "nu", "nugget", "likelihood", "trial"))

start.time <- Sys.time()
for (ein in unique(df$EIN2)){
      print(ein)
      df.sub <- filter(df, EIN2==ein)
      likelihood_wrapper <- function(pars.vec){
            return(-1 * get_likelihood(row = pars.vec,
                                  dist_mat = dist_mat,
                                  rho = rho,
                                  all_years = df.sub$YEAR + 1,
                                  data = df.sub$LOG_REV,
                                  compute.sigma = TRUE))
      }
      initial.conds <- combos[sample(nrow(combos), 15),]
      for (i in 1:nrow(initial.conds)){
            res <- constrOptim(theta = as.numeric(as.vector(initial.conds[i,])), 
                               f = likelihood_wrapper,
                               grad = NULL,
                               ui = cbind(c(1,0),c(0,1)),
                               ci = c(0.001,0))
            max_L.constrainNM[nrow(max_L.constrainNM)+1,1] <- ein
            max_L.constrainNM[nrow(max_L.constrainNM),2:ncol(max_L.constrainNM)] <- c(c(initial.conds[i,1], initial.conds[i,2], res$par[1], res$par[2], -1*res$value, i))
      }
}
print(Sys.time() - start.time)

#max_L.Grid <- readRDS("MODEL/outlier_detection/grid_max_likelihoods.rds")
#max_L.Grid <- rownames_to_column(as.data.frame(do.call(rbind, lapply(X = max_L.Grid, FUN = unlist))), var = "EIN") 
#maxes.constrainNM <- max_L.constrainNM |> group_by(EIN) |> summarise(MAX = max(likelihood)) 
#saveRDS(maxes.constrainNM, "MODEL/outlier_detection/constrainNM_max_likelihoods.rds")

#full_join(max_L.Grid, maxes.constrainNM, by = "EIN", suffix = c(".grid", ".NM")) |> mutate(BIGGER = (V1 <= MAX))

#saveRDS(max_L.constrainNM |> inner_join(maxes.constrainNM, by = "EIN") |> filter(likelihood == MAX) |> select(-MAX), "MODEL/outlier_detection/constrainNM_results.rds")
```


```{r, echo = FALSE, eval = FALSE}
res <- readRDS("MODEL/outlier_detection/constrainNM_results.rds")
rownames(res) <- res[,"EIN"]
res <- res |> mutate(sigma.squared = 0)

all_predictions = list()
all_candidates = list()
all_se = list()

mu_1 <- 0
# Looping over all organizations
start.time <- Sys.time()
for (ein in unique(df$EIN2)){
      df.sub <- filter(df, EIN2==ein)
      all_years <- df.sub$YEAR + 1 # all the years we have data for that org
      mu_2 <- numeric(nrow(df.sub) - 1) # all zeros
      
      predictions <- numeric(length(all_years)) # initialize
      standard_errors <- numeric(length(all_years)) # initialize
      
      # Generate Matern covariance matrix using "best" hyperparameters
      mat_cov <- Matern(d = dist_mat, 
                        smoothness = res[ein,]$nu, 
                        range = rho, 
                        phi = 1) + diag(res[ein,]$nugget, dim(dist_mat)[1])
      
      sigma.squared <- (1/length(df.sub$LOG_REV)) * (df.sub$LOG_REV %*% solve(mat_cov[all_years, all_years]) %*% df.sub$LOG_REV)[1,1]
      mat_cov <- sigma.squared * mat_cov
      
      res[ein,]$sigma.squared <- sigma.squared
      for(i in 1:length(all_years)){
            # Leave out i-th year
            log_revenue <- (df |> filter(EIN2 == ein & YEAR != all_years[i]-1))$LOG_REV
            
            SIGMA.11 <- mat_cov[all_years[i], all_years[i]]
            SIGMA.22.inv <- solve(mat_cov[all_years[-i], all_years[-i]])
            SIGMA.12 <- mat_cov[all_years[i], all_years[-i], drop = FALSE]
            
            predictions[i] <- mu_1 + (SIGMA.12 %*% SIGMA.22.inv %*% (log_revenue - mu_2)) #mu_bar
            standard_errors[i] <- sqrt(as.numeric(SIGMA.11 - (SIGMA.12 %*% SIGMA.22.inv %*% t(SIGMA.12))))
      }
      
      residuals <- abs(((df |> filter(EIN2 == ein))$LOG_REV - predictions) / standard_errors) # standardized residuals
      
      all_predictions[[ein]] <- predictions
      all_se[[ein]] <- standard_errors
      all_candidates[[ein]] <-  all_years[which(residuals > 3)] - 1 + 1989
      
      p <- plot_true_vs_pred(df = df, 
                             ein = ein, 
                             predictions = predictions, 
                             standard_errors = standard_errors, 
                             all_years = all_years, 
                             candidate_outliers = all_candidates[ein], 
                             combo = res[ein,], label = ein)
      print(p)
}

print(Sys.time() - start.time)
```


```{r}
saveRDS(res, "MODEL/outlier_detection/constrainNM_results.rds")
saveRDS(all_predictions, "MODEL/outlier_detection/constrainNM_predictions.rds")
saveRDS(all_se, "MODEL/outlier_detection/constrainNM_standard_errors.rds")
saveRDS(all_candidates, "MODEL/outlier_detection/constrainNM_candidates.rds")
```


## Bayesian Optimization
```{r, message=F, echo = F, eval = F}
library(fields)
library(readr)
library(tidyverse, warn.conflicts = FALSE)
library(data.table)
library(dplyr, warn.conflicts = FALSE)
library(ggplot2)
library(tidyr)
library(mvtnorm)
library(devtools)
#library(ParBayesianOptimization)
load_all('ParBayesianOptimization')
source("SCRIPTS/outlier_detection_helper.R")
```

```{r, eval = FALSE, echo = FALSE}
df <- as.data.table(read_csv("small_test.csv", show_col_types = FALSE)) 

# center the data
df <- df |>
      group_by(EIN2) |>
      mutate(LOG_REV = LOG_REV - mean(LOG_REV)) |>
      ungroup()

# distance matrix of years
dist_mat <- dist(sort(unique(df$YEAR)), diag=TRUE, upper=TRUE)
dist_mat <- as.matrix(dist_mat)

# normalize
dist_mat <- (dist_mat - min(dist_mat)) / (max(dist_mat) - min(dist_mat))
```

```{r, eval = FALSE, echo = FALSE}
bounds <- list(nu = c(0.025,2.5), nugget = c(0,2.5), sigma.squared = c(0.025, 1.5))
opt_info <- list()

start.time <- Sys.time() # about two minutes per org / took about 50 minutes for whole dataset
for (ein in unique(df$EIN2)){
      print(ein)
      df.subset <- df |> filter(EIN2 == ein)
      
      # need to define different wrapper function per org to pass to bayesOpt since data and years differs org to org
      get_likelihood_bayesopt_wrapper <- function(nu, nugget, sigma.squared) {
            return(list(Score = get_likelihood_bayesopt(distance.matrix = dist_mat, 
                                     data = df.subset$LOG_REV, 
                                     years = df.subset$YEAR + 1, 
                                     nu, nugget, sigma.squared)))
      } 
      
      opt_info[[ein]] <- bayesOpt(FUN = get_likelihood_bayesopt_wrapper,
                                     bounds = bounds,
                                     initPoints = 5,
                                     iters.n = 50,
                                     plotProgress = FALSE,
                                     verbose = 0)
}
print(Sys.time() - start.time)
```

```{r}
# Trying stuff in parallel
library(doParallel)

bounds <- list(nu = c(0.025,2.5), nugget = c(0,2.5), sigma.squared = c(0.025, 1.5))
combos <- expand.grid(nu = seq(from = 0.05, to = 2.5, by = 0.245), 
                      nugget = seq(from = 0, to = 2, by = 0.2), 
                      sigma.squared = seq(from = 0.05, to = 0.95, by = 0.1))

opt_info <- list()
# 15 minutes for initPoints = 605, iters.n = 28, iters.k = 2 on 4 clusters
# 51 minutes for initPoints = 1210, iters.n = 20, iters.k = 2 on 4 clusters
# 28 minutes for initPoints = 605, iters.n = 300, iters.k = 6 on 6 clusters
start.time.outer <- Sys.time() #"EIN-75-2897026", "EIN-62-6041523", "EIN-36-4556466", "EIN-04-2503758", "EIN-15-6016932", "EIN-22-1487233"
for (ein in c("EIN-75-2897026")){
      print(ein)
      df.subset <- df |> filter(EIN2 == ein)
      
      # need to define different wrapper function per org to pass to bayesOpt since data and years differs org to org
      get_likelihood_bayesopt_wrapper <- function(nu, nugget, sigma.squared) {
            return(list(Score = get_likelihood_bayesopt(distance.matrix = dist_mat, 
                                     data = df.subset$LOG_REV, 
                                     years = df.subset$YEAR + 1, 
                                     nu, nugget, sigma.squared)))
      } 
      
      cl <- makeCluster(6) # 6 cl, iters.k=2 - 2.5 min; 6 cl, iters.k=4 - 1.3 min; 6 cl, iters.k=1 - 2.4 min; no clusters - 9 min
      registerDoParallel(cl)
      clusterExport(cl,c('dist_mat','df.subset'))
      clusterEvalQ(cl,expr= {
        library(mvtnorm)
        library(fields)
        source("SCRIPTS/outlier_detection_helper.R")
      })
      
      start.time.inner <- Sys.time()
      opt_info[[ein]] <- bayesOpt(FUN = get_likelihood_bayesopt_wrapper,
                                  bounds = bounds,
                                  initPoints = 605,
                                  iters.n = 300,
                                  iters.k = 6,
                                  plotProgress = FALSE,
                                  verbose = 2,
                                  parallel = TRUE)
      print(Sys.time() - start.time.inner)
      stopCluster(cl)
}
print(Sys.time() - start.time.outer)

max_L.grid <- readRDS("MODEL/outlier_detection/grid_max_likelihoods.rds")
max_L.bayes <- list()
for (ein in names(opt_info)){
      # Need to grab the row in scoreSummary corresponding to the "best parameters" determined by bayesOpt
      best_pars.bayes <- getBestPars(opt_info[[ein]])
      bScore <- (opt_info[[ein]]$scoreSummary |> filter(nu == best_pars.bayes$nu & nugget == best_pars.bayes$nugget & sigma.squared == best_pars.bayes$sigma.squared))
      max_L.bayes[[ein]] <- bScore$Score
      # Print the score (likelihood) corresponding to "best BayesOpt parameters", the likelihood from "best GridOpt parameters
      print(paste(ein, bScore$Score, max_L.grid[[ein]], (bScore$Score >= max_L.grid[[ein]]), sep = ", "))
}
```


```{r, echo = FALSE, eval = FALSE}
all_predictions = list()
all_candidates = list()
all_se = list()
all_best_params = list()

mu_1 <- 0
# Looping over all organizations
start.time <- Sys.time()
for (ein in unique(df$EIN2)){
      all_years <- (df |> filter(EIN2 == ein))$YEAR + 1 # all the years we have data for that org
      mu_2 <- numeric(nrow(df |> filter(EIN2 == ein)) - 1) # all zeros
      
      predictions <- numeric(length(all_years)) # initialize
      standard_errors <- numeric(length(all_years)) # initialize
      
      best.pars <- getBestPars(opt_info[[ein]])
      all_best_params[[ein]] <- best.pars
      
      # Generate Matern covariance matrix using "best" hyperparameters
      mat_cov <- Matern(d = dist_mat, 
                        smoothness = best.pars$nu, 
                        range = 1, 
                        phi = best.pars$sigma.squared) + diag(best.pars$nugget, dim(dist_mat)[1])
      
      # Train different model per org leave-one-out style
      for(i in 1:length(all_years)){
            # Leave out i-th year
            log_revenue <- (df |> filter(EIN2 == ein & YEAR != all_years[i]-1))$LOG_REV
            
            SIGMA.11 <- mat_cov[all_years[i], all_years[i]]
            SIGMA.22.inv <- solve(mat_cov[all_years[-i], all_years[-i]])
            SIGMA.12 <- mat_cov[all_years[i], all_years[-i], drop = FALSE]
            
            predictions[i] <- mu_1 + (SIGMA.12 %*% SIGMA.22.inv %*% (log_revenue - mu_2)) #mu_bar
            standard_errors[i] <- sqrt(as.numeric(SIGMA.11 - (SIGMA.12 %*% SIGMA.22.inv %*% t(SIGMA.12))))
      }
      
      residuals <- abs(((df |> filter(EIN2 == ein))$LOG_REV - predictions) / standard_errors) # standardized residuals
      
      all_predictions[[ein]] <- predictions
      all_se[[ein]] <- standard_errors
      all_candidates[[ein]] <-  all_years[which(residuals > 3)] - 1 + 1989
      
      p <- plot_true_vs_pred(df, ein, predictions, standard_errors, all_years, all_candidates[ein], best.pars)
      print(p)
}

print(Sys.time() - start.time)
```

```{r}
saveRDS(all_predictions, "MODEL/outlier_detection/bayesOpt_predictions.rds")
saveRDS(all_se, "MODEL/outlier_detection/bayesOpt_standard_errors.rds")
saveRDS(all_candidates, "MODEL/outlier_detection/bayesOpt_candidates.rds")
saveRDS(all_best_params, "MODEL/outlier_detection/bayesOpt_best_params.rds")
saveRDS(opt_info, "MODEL/outlier_detection/bayesOpt_opt_info.rds")
```


## Grid Search
```{r, message=F, echo = FALSE, eval = FALSE}
library(fields)
library(readr)
library(tidyverse, warn.conflicts = FALSE)
library(data.table)
library(dplyr, warn.conflicts = FALSE)
library(ggplot2)
library(tidyr)
library(mvtnorm)
source("SCRIPTS/outlier_detection_helper.R")
```


```{r, echo = FALSE, eval = FALSE}
df <- as.data.table(read_csv("small_test.csv", show_col_types = FALSE)) 

# center the data
df <- df |>
      group_by(EIN2) |>
      mutate(LOG_REV = LOG_REV - mean(LOG_REV)) |>
      ungroup()

# distance matrix of years
dist_mat <- dist(sort(unique(df$YEAR)), diag=TRUE, upper=TRUE)
dist_mat <- as.matrix(dist_mat)

# normalize
min_val <- min(dist_mat)
max_val <- max(dist_mat)
dist_mat <- (dist_mat - min_val) / (max_val - min_val)

# Set up ranges for Matern covariance matrix hyperparameters
rho <- 1

nu_vec <- seq(from = 0.05, to = 2.5, by = 0.245)
nugget_vec <- seq(from = 0, to = 2, by = 0.2)
sigma_squared_vec <- seq(from = 0.05, to = 0.95, by = 0.1)

# All possible combinations of hyperparameters
combos <- expand.grid(nu = nu_vec, nugget = nugget_vec, sigma.squared = sigma_squared_vec)

# Grid Search: Looping over all organizations to find best set of hyperparameters
max_likelihoods = list()
max_likelihoods_idx = list()
all_likelihoods = list()

start.time <- Sys.time()
for (ein in unique(df$EIN2)){
      all_years <- (df |> filter(EIN2 == ein))$YEAR + 1 # all the years we have data for that org
      
      # get the likelihood for each combination of parameters
      likelihoods <- apply(combos, 
                           MARGIN = 1, 
                           function(row) return(get_likelihood(row,
                                          dist_mat = dist_mat,
                                          rho = rho,
                                          all_years = all_years,
                                          data = (df |> filter(EIN2 == ein))$LOG_REV))
                           )
      all_likelihoods[[ein]] <- likelihoods
      max_likelihoods[[ein]] <- max(likelihoods)
      max_likelihoods_idx[[ein]] <- which.max(likelihoods)
}

print(Sys.time() - start.time)

best_combos <- combos[as.vector(unlist(max_likelihoods_idx)),]
row.names(best_combos) <- names(max_likelihoods_idx)

best_combos
```

```{r, echo = FALSE, eval = FALSE}
all_predictions = list()
all_candidates = list()
all_se = list()

mu_1 <- 0
# Looping over all organizations
start.time <- Sys.time()
for (ein in unique(df$EIN2)){
      all_years <- (df |> filter(EIN2 == ein))$YEAR + 1 # all the years we have data for that org
      mu_2 <- numeric(nrow(df |> filter(EIN2 == ein)) - 1) # all zeros
      
      predictions <- numeric(length(all_years)) # initialize
      standard_errors <- numeric(length(all_years)) # initialize
      
      # Generate Matern covariance matrix using "best" hyperparameters
      mat_cov <- Matern(d = dist_mat, 
                        smoothness = best_combos[ein,1], 
                        range = rho, 
                        phi = best_combos[ein,3]) + diag(best_combos[ein,2], dim(dist_mat)[1])
      
      for(i in 1:length(all_years)){
            # Leave out i-th year
            log_revenue <- (df |> filter(EIN2 == ein & YEAR != all_years[i]-1))$LOG_REV
            
            SIGMA.11 <- mat_cov[all_years[i], all_years[i]]
            SIGMA.22.inv <- solve(mat_cov[all_years[-i], all_years[-i]])
            SIGMA.12 <- mat_cov[all_years[i], all_years[-i], drop = FALSE]
            
            predictions[i] <- mu_1 + (SIGMA.12 %*% SIGMA.22.inv %*% (log_revenue - mu_2)) #mu_bar
            standard_errors[i] <- sqrt(as.numeric(SIGMA.11 - (SIGMA.12 %*% SIGMA.22.inv %*% t(SIGMA.12))))
      }
      
      residuals <- abs(((df |> filter(EIN2 == ein))$LOG_REV - predictions) / standard_errors) # standardized residuals
      
      all_predictions[[ein]] <- predictions
      all_se[[ein]] <- standard_errors
      all_candidates[[ein]] <-  all_years[which(residuals > 3)] - 1 + 1989
      
      p <- plot_true_vs_pred(df, ein, predictions, standard_errors, all_years, all_candidates[ein], best_combos[ein,])
      print(p)
}

print(Sys.time() - start.time)
```

```{r}
saveRDS(all_predictions, "MODEL/outlier_detection/grid_predictions.rds")
saveRDS(all_se, "MODEL/outlier_detection/grid_standard_errors.rds")
saveRDS(all_candidates, "MODEL/outlier_detection/grid_candidates.rds")
saveRDS(best_combos, "MODEL/outlier_detection/grid_best_params.rds")
saveRDS(max_likelihoods, "MODEL/outlier_detection/grid_max_likelihoods.rds")
```

```{r, echo = FALSE}
df <- as.data.table(read_csv("small_test.csv", show_col_types = FALSE)) |>
      group_by(EIN2) |>
      mutate(LOG_REV = LOG_REV - mean(LOG_REV)) |>
      ungroup()

predictions <- readRDS("MODEL/outlier_detection/grid_predictions.rds")
standard_errors <- readRDS("MODEL/outlier_detection/grid_standard_errors.rds")
all_candidates <- readRDS("MODEL/outlier_detection/grid_candidates.rds")
best_combos <- readRDS("MODEL/outlier_detection/grid_best_params.rds")

for (ein in unique(df$EIN2)){
      all_years <- (df |> filter(EIN2 == ein))$YEAR + 1
      p <- plot_true_vs_pred(df, ein, predictions[[ein]], standard_errors[[ein]], all_years, all_candidates[[ein]], best_combos[ein,], label = ein)
      print(p)
}
```


### Response surfaces
```{r, eval = FALSE, echo = FALSE}
library(cowplot)

# ein <- "EIN-77-0368378"
# p <- plot_surface_nu(ein, combos, all_likelihoods, sigma_fixed = best_combos[ein,]$sigma.squared, nu_fixed = best_combos[ein,]$nu, nugget_fixed = best_combos[ein,]$nugget)
# print(p)

for (ein in unique(df$EIN2)){
      p <- plot_heatmap(ein, combos, all_likelihoods, 
                           sigma_fixed = best_combos[ein,]$sigma.squared, 
                           nu_fixed = best_combos[ein,]$nu, 
                           nugget_fixed = best_combos[ein,]$nugget)
      print(p)
}
```


```{r, eval = FALSE, echo = FALSE}
library(plotly)
ein = "EIN-20-3754055"
# x = nugget, y = sigma^2
p <- plot_surface(ein, combos, all_likelihoods, fixed = "nu", fixed_val = best_combos[ein,]$nu)
p
```


## Single org
```{r, eval = FALSE, echo = FALSE}
ein = "EIN-20-3754055"
all_years <- (df |> filter(EIN2 == ein))$YEAR + 1 # all the years we have data for that org

apply(combos |> head(10), 
      MARGIN = 1, 
      function(row) return(get_likelihood(row,
                                          dist_mat = dist_mat,
                                          rho = rho,
                                          all_years = all_years,
                                          data = (df |> filter(EIN2 == ein))$LOG_REV_CENTERED))
      )

for (i in seq(1,5,1)){
      # Compute Matérn Covariance Matrix
      mat_cov <- Matern(d = dist_mat, 
                        smoothness = combos[i,1], 
                        range = rho, 
                        phi = combos[i,3]) + diag(combos[i,2], dim(dist_mat)[1])
      
      print(mat_cov[all_years, all_years])
      data <- (df |> filter(EIN2 == ein))$LOG_REV_CENTERED
      print(data)
      # Compute likelihood
      likelihood <- dmvnorm(data, 
                            mean = rep(0, length(data)), 
                            sigma = mat_cov[all_years, all_years],
                            log = TRUE)
      
      print(likelihood)
}

```

# Test Run (no optimization)
## Setup
```{r, message=FALSE, eval=FALSE}
library(fields)
library(readr)
library(tidyverse, warn.conflicts = FALSE)
library(data.table)
library(dplyr, warn.conflicts = FALSE)
library(ggplot2)
library(tidyr)

df <- as.data.table(read_csv("small_test.csv", show_col_types = FALSE)) 

# center the data
df <- df |>
      group_by(EIN2) |>
      mutate(LOG_REV = LOG_REV - mean(LOG_REV)) |> #mutate(LOG_REV_CENTERED = LOG_REV - mean(LOG_REV))
      ungroup()

# distance matrix of years
dist_mat <- dist(sort(unique(df$YEAR)), diag=TRUE, upper=TRUE)
dist_mat <- as.matrix(dist_mat)

# normalize
min_val <- min(dist_mat)
max_val <- max(dist_mat)
dist_mat <- (dist_mat - min_val) / (max_val - min_val)

# Matérn covariance
nu <- 0.5
rho <- 1
sigma_squared <- 1
nugget <- 0.1

mat_cov <- Matern(d = dist_mat, smoothness = nu, range = rho, phi = sigma_squared) + diag(nugget, dim(dist_mat)[1])

mu_1 <- 0
```

## All orgs
```{r, eval=FALSE}
#ein <- "EIN-77-0368378"
#predictions <- all_predictions[ein]
#standard_errors <- all_se[ein]
#candidate_outliers <- all_candidates[ein]
#all_years <- (df |> filter(EIN2 == ein))$YEAR + 1
#residuals <- abs(filter(df, EIN2 == ein)$LOG_REV - unlist(predictions)) / unlist(standard_errors)

# Select data specific to this org, add predictions, standard errors, and outlier flag to data
plot_true_vs_pred <- function(df, ein, predictions, standard_errors, all_years, candidate_outliers){
      df_long <- df |> filter(EIN2==ein) |>
            mutate(OUTLIER = case_when(TAX_YEAR %in% unlist(candidate_outliers) ~ "Candidate Outlier", .default = "Non-outlier"))
      df_long$PRED <- unlist(predictions)
      df_long$SE <- unlist(standard_errors)

      df_long <- df_long |>
            pivot_longer(cols = c(LOG_REV, PRED), names_to = "Variable", values_to = "Value")
      
      # Add a column to flag outliers (TRUE if OUTLIER is not NA), add confidence intervals
      df_long <- df_long |>
            mutate(CI.LOWER = case_when(
                  Variable == "LOG_REV" ~ 0,
                  Variable == "PRED" ~ qt(0.95, df = length(all_years)-1) * SE)) |>
            mutate(CI.UPPER = case_when(
                  Variable == "LOG_REV" ~ 0,
                  Variable == "PRED" ~ qt(0.95, df = length(all_years)-1) * SE))
      
      # Base plot of true versus predicted with error bars on predicted
      p <- ggplot(df_long, aes(x = TAX_YEAR, y = Value, color = Variable, shape = OUTLIER)) +
            geom_point(size=3) +
            geom_line(aes(group = Variable)) +
            geom_errorbar(data = (df_long |> filter(Variable == "PRED")),aes(ymin = Value - CI.LOWER, ymax = Value + CI.UPPER,group = Variable)) +
            labs(x = "Tax Year", y = "Log Revenue", title = paste("Observed vs Predicted Log Revenue:", ein)) +
            scale_color_manual(values = c("LOG_REV" = "#1796D2", "PRED" = "#55B748"), 
                               labels = c("LOG_REV" = "True", "PRED" = "Predicted"), 
                               name = "Legend") +
            scale_shape_manual(values = c("Candidate Outlier" = 8, "Non-outlier" = 16)) 
      
      # Highlight outliers
      #p <- p + geom_vline(xintercept = candidate_outliers, color = "black", alpha = 0.5, linetype = "dashed", show.legend = FALSE)
      
      return(p)
}
```


```{r, eval=FALSE}
all_predictions = list()
all_candidates = list()
all_se = list()

# Looping over all organizations
for (ein in unique(df$EIN2)){
      all_years <- (df |> filter(EIN2 == ein))$YEAR + 1 # all the years we have data for that org
      mu_2 <- numeric(nrow(df |> filter(EIN2 == ein)) - 1) # all zeros
      
      predictions <- numeric(length(all_years)) # initialize
      standard_errors <- numeric(length(all_years)) # initialize
      for(i in 1:length(all_years)){
            # Leave out i-th year
            log_revenue <- (df |> filter(EIN2 == ein & YEAR != all_years[i]-1))$LOG_REV
            
            SIGMA.11 <- mat_cov[all_years[i], all_years[i]]
            SIGMA.22.inv <- solve(mat_cov[all_years[-i], all_years[-i]])
            SIGMA.12 <- mat_cov[all_years[i], all_years[-i], drop = FALSE]
            
            predictions[i] <- mu_1 + (SIGMA.12 %*% SIGMA.22.inv %*% (log_revenue - mu_2)) #mu_bar
            standard_errors[i] <- sqrt(as.numeric(SIGMA.11 - (SIGMA.12 %*% SIGMA.22.inv %*% t(SIGMA.12))))
      }
      
      residuals <- abs(((df |> filter(EIN2 == ein))$LOG_REV - predictions) / standard_errors) # (true - predicted) / (Stnd Error of Predictions)
      
      all_predictions[[ein]] <- predictions
      all_se[[ein]] <- standard_errors
      all_candidates[[ein]] <-  all_years[which(residuals > 3)] - 1 + 1989
      
      p <- plot_true_vs_pred(df, ein, predictions, standard_errors, all_years, all_candidates[ein])
      print(p)
}

```

```{r, eval=FALSE}
all_sig_squared <- lapply(all_se, function(x) x^2)
max(sapply(all_sig_squared, max))
min(sapply(all_sig_squared, min))
```


## Single Organization (TEST)
```{r, eval = FALSE, echo = FALSE}
# Trying for a single organization 
ein <- "EIN-04-2503758"

# Train GPs
all_years <- (df |> filter(EIN2 == ein))$YEAR + 1 # all the years we have data for that org
mu_2 <- numeric(nrow(df |> filter(EIN2 == ein)) - 1) # all zeros

predictions <- numeric(length(all_years)) # initialize
standard_errors <- numeric(length(all_years)) # initialize
for(i in 1:length(all_years)){
      # Leave out i-th year
      log_revenue <- (df |> filter(EIN2 == ein & YEAR != all_years[i]-1))$LOG_REV
      
      SIGMA.11 <- mat_cov[all_years[i], all_years[i]]
      SIGMA.22.inv <- solve(mat_cov[all_years[-i], all_years[-i]])
      SIGMA.12 <- mat_cov[all_years[i], all_years[-i], drop = FALSE]
      
      predictions[i] <- mu_1 + (SIGMA.12 %*% SIGMA.22.inv %*% (log_revenue - mu_2)) #mu_bar
      standard_errors[i] <- sqrt(as.numeric(SIGMA.11 - (SIGMA.12 %*% SIGMA.22.inv %*% t(SIGMA.12))))
}

residuals <- abs(((df |> filter(EIN2 == ein))$LOG_REV - predictions) / standard_errors) # (true - predicted) / (Stnd Error of Predictions)

candidate_outliers <- all_years[which(residuals > 3)] - 1 + 1989
```


```{r, eval = FALSE, echo = FALSE}
# Select data specific to this org, add predictions, standard errors, and outlier flag to data
df_long <- df |> 
      filter(EIN2==ein) |> 
      mutate(PRED = predictions,
             OUTLIER = case_when(TAX_YEAR %in% candidate_outliers ~ "Candidate Outlier", .default = "Non-outlier"),
             SE = standard_errors)

df_long <- df_long |>
      pivot_longer(cols = c(LOG_REV, PRED), names_to = "Variable", values_to = "Value")

# Add a column to flag outliers (TRUE if OUTLIER is not NA), add confidence intervals
df_long <- df_long |>
      mutate(IsOutlier = !is.na(OUTLIER)) |>
      mutate(CI.LOWER = case_when(
            Variable == "LOG_REV" ~ 0,
            Variable == "PRED" ~ qt(0.95, df = length(all_years)-1) * SE)) |>
      mutate(CI.UPPER = case_when(
            Variable == "LOG_REV" ~ 0,
            Variable == "PRED" ~ qt(0.95, df = length(all_years)-1) * SE))

# Base plot of true versus predicted with error bars on predicted
p <- ggplot(df_long, aes(x = TAX_YEAR, y = Value, color = Variable, shape = OUTLIER)) +
      geom_point(size=3) +
      geom_line(aes(group = Variable)) +
      geom_errorbar(data = (df_long |> filter(Variable == "PRED")),aes(ymin = Value - CI.LOWER, ymax = Value + CI.UPPER,group = Variable)) +
      labs(x = "Tax Year", y = "Log Revenue", title = "Observed vs Predicted Log Revenue") +
      scale_color_manual(values = c("LOG_REV" = "#1796D2", "PRED" = "#55B748"), 
                         labels = c("LOG_REV" = "True", "PRED" = "Predicted"), 
                         name = "Legend") +
      scale_shape_manual(values = c("Candidate Outlier" = 8, "Non-outlier" = 16)) 

# Highlight outliers
p <- p + geom_vline(xintercept = candidate_outliers, color = "black", alpha = 0.5, linetype = "dashed", show.legend = FALSE)
print(p)
```
